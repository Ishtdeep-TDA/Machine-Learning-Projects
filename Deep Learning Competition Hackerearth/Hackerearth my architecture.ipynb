{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "#from tensorflow.keras import Sequential\n",
    "#from tensorflow.keras.optimizers import Adam\n",
    "#from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
    "#from tensorflow.keras.layers import Dense, Conv2D, Flatten, GlobalAveragePooling2D, Dropout\n",
    "#from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import MaxPooling2D,Dense, Conv2D, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"E:\\Data Science\\Kaggle Competitions dataset\\Hackerearth gala\\dataset/train.csv\")\n",
    "df_test = pd.read_csv(\"E:\\Data Science\\Kaggle Competitions dataset\\Hackerearth gala\\dataset/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image7042.jpg</td>\n",
       "      <td>Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image3327.jpg</td>\n",
       "      <td>misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image10335.jpg</td>\n",
       "      <td>Attire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image8019.jpg</td>\n",
       "      <td>Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image2128.jpg</td>\n",
       "      <td>Attire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Image   Class\n",
       "0   image7042.jpg    Food\n",
       "1   image3327.jpg    misc\n",
       "2  image10335.jpg  Attire\n",
       "3   image8019.jpg    Food\n",
       "4   image2128.jpg  Attire"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Food                    2278\n",
       "Attire                  1691\n",
       "misc                    1271\n",
       "Decorationandsignage     743\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True image size\n",
    "IMG_WIDTH = 120\n",
    "IMG_HEIGHT = 80\n",
    "\n",
    "def preprocess_image(image, sigmaX=10):\n",
    "    \"\"\"\n",
    "    The whole preprocessing pipeline:\n",
    "    1. Read in image\n",
    "    2. Apply masks\n",
    "    3. Resize image to desired size\n",
    "    4. Add Gaussian noise to increase Robustness\n",
    "    \n",
    "    :param img: A NumPy Array that will be cropped\n",
    "    :param sigmaX: Value used for add GaussianBlur to the image\n",
    "    \n",
    "    :return: A NumPy array containing the preprocessed image\n",
    "    \"\"\"\n",
    "    image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n",
    "    image = np.array(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = cv2.imread(r'E:/Data Science/Kaggle Competitions dataset/Hackerearth gala/dataset/Train Images/image7042.jpg')\n",
    "#cv2.imshow('image',img)\n",
    "#cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKING SURE ALL IMAGES ARE OF SAME SIZE\n",
    "\n",
    "diff_shape = set()\n",
    "PATH = \"E:/Data Science/Kaggle Competitions dataset/Hackerearth gala/dataset/Train Images/\"\n",
    "for i in range(df.shape[0]):\n",
    "    temp = PATH + str(df[\"Image\"][i])\n",
    "    img = cv2.imread(temp)\n",
    "    diff_shape.add(img.shape[0])\n",
    "    diff_shape.add(img.shape[1])\n",
    "    diff_shape.add(img.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "# resizing the image to the size of efficientnet\n",
    "#IMG_WIDTH = 456\n",
    "#IMG_HEIGHT = 456\n",
    "\n",
    "# Add Image augmentation to our generator\n",
    "train_datagen = ImageDataGenerator(rotation_range=360,\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True,\n",
    "                                   validation_split=0.2,\n",
    "                                   preprocessing_function=preprocess_image, \n",
    "                                   rescale=1 / 128.)\n",
    "train_generator = train_datagen.flow_from_dataframe(df, \n",
    "                                                    x_col='Image', \n",
    "                                                    y_col='Class',\n",
    "                                                    directory = PATH,\n",
    "                                                    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    class_mode='categorical', \n",
    "                                                    subset='training')\n",
    "val_generator = train_datagen.flow_from_dataframe(df, \n",
    "                                                  x_col='Image', \n",
    "                                                  y_col='Class',\n",
    "                                                  directory = PATH,\n",
    "                                                  target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                  batch_size=BATCH_SIZE,\n",
    "                                                  class_mode='categorical',\n",
    "                                                  subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## seems like efficient net is too large\n",
    "# can try to freeze some layers\n",
    "\n",
    "\n",
    "#from keras_efficientnets import EfficientNetB5\n",
    "#effnet = EfficientNetB5(input_shape=(456,456,3),\n",
    "#                        weights='imagenet',\n",
    "#                        include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#effnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "l2 = l2(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \"\"\"\n",
    "    A custom implementation of EfficientNetB5\n",
    "    for the APTOS 2019 competition\n",
    "    (Regression)\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters = 100, kernel_size = (3,3),padding = 'Same',data_format=\"channels_last\", strides = 1, \n",
    "                 activation ='relu', input_shape = (IMG_HEIGHT,IMG_WIDTH,3),kernel_initializer = \"lecun_uniform\",kernel_regularizer = l2))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "    \n",
    "    model.add(Conv2D(filters = 200, kernel_size = (3,3),padding = 'Same', strides = 1, \n",
    "                 activation ='relu',kernel_initializer = \"lecun_uniform\",kernel_regularizer = l2))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "    \n",
    "    model.add(Conv2D(filters = 100, kernel_size = (5,5),padding = 'same', strides = 1, \n",
    "                 activation ='relu',kernel_initializer = \"lecun_uniform\",kernel_regularizer = l2))\n",
    "    model.add(Conv2D(filters = 100, kernel_size = (5,5),padding = 'same', strides = 1, \n",
    "                 activation ='relu',kernel_initializer = \"lecun_uniform\",kernel_regularizer = l2))\n",
    "    model.add(Conv2D(filters = 100, kernel_size = (5,5),padding = 'same', strides = 1, \n",
    "                 activation ='relu',kernel_initializer = \"lecun_uniform\",kernel_regularizer = l2))\n",
    "    model.add(Conv2D(filters = 100, kernel_size = (7,7),padding = 'same', strides = 1, \n",
    "                 activation ='relu',kernel_initializer = \"lecun_uniform\",kernel_regularizer = l2))\n",
    "    model.add(Conv2D(filters = 100, kernel_size = (7,7),padding = 'same', strides = 1, \n",
    "                 activation ='relu',kernel_initializer = \"lecun_uniform\",kernel_regularizer = l2))\n",
    "    \n",
    "\n",
    "    model.add(Conv2D(filters = 100, kernel_size = (7,7),padding = 'same', strides = 1, \n",
    "                 activation ='relu',kernel_initializer = \"lecun_uniform\",kernel_regularizer = l2))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(filters = 100, kernel_size = (5,5),padding = 'same', strides = 1, \n",
    "                 activation ='relu',kernel_initializer = \"lecun_uniform\",kernel_regularizer = l2))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(20, activation=\"relu\"))\n",
    "    model.add(Dense(4, activation=\"softmax\"))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=\"adam\", \n",
    "                  metrics=['categorical_crossentropy', 'mse'])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "# Initialize model\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='auto', verbose=1, patience=12)\n",
    "rlr = ReduceLROnPlateau(monitor='val_loss', \n",
    "                        factor=0.5, \n",
    "                        patience=15,\n",
    "                        verbose=1, \n",
    "                        mode='auto', \n",
    "                        epsilon=0.00001)\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "mc = ModelCheckpoint(r'E:\\Data Science\\Kaggle Competitions dataset\\Hackerearth gala\\dataset/my_architecture.h5', monitor='categorical_crossentropy', mode='min', verbose=1, save_best_only=True)\n",
    "# Begin training\n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "                    epochs=100,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps = val_generator.samples // BATCH_SIZE,\n",
    "                    callbacks=[mc, rlr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
