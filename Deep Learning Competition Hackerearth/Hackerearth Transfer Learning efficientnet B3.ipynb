{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "#from tensorflow.keras import Sequential\n",
    "#from tensorflow.keras.optimizers import Adam\n",
    "#from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
    "#from tensorflow.keras.layers import Dense, Conv2D, Flatten, GlobalAveragePooling2D, Dropout\n",
    "#from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Dense, Conv2D, Flatten, GlobalAveragePooling2D, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"E:\\Data Science\\Kaggle Competitions dataset\\Hackerearth gala\\dataset/train.csv\")\n",
    "df_test = pd.read_csv(\"E:\\Data Science\\Kaggle Competitions dataset\\Hackerearth gala\\dataset/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True image size\n",
    "IMG_WIDTH = 120\n",
    "IMG_HEIGHT = 80\n",
    "\n",
    "def preprocess_image(image, sigmaX=10):\n",
    "    \"\"\"\n",
    "    The whole preprocessing pipeline:\n",
    "    1. Read in image\n",
    "    2. Apply masks\n",
    "    3. Resize image to desired size\n",
    "    4. Add Gaussian noise to increase Robustness\n",
    "    \n",
    "    :param img: A NumPy Array that will be cropped\n",
    "    :param sigmaX: Value used for add GaussianBlur to the image\n",
    "    \n",
    "    :return: A NumPy array containing the preprocessed image\n",
    "    \"\"\"\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n",
    "    image = cv2.addWeighted (image,4, cv2.GaussianBlur(image, (0,0) ,sigmaX), -4, 128)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = cv2.imread(r'E:/Data Science/Kaggle Competitions dataset/Hackerearth gala/dataset/Train Images/image7042.jpg')\n",
    "#cv2.imshow('image',img)\n",
    "#cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKING SURE ALL IMAGES ARE OF SAME SIZE\n",
    "\n",
    "#diff_shape = set()\n",
    "PATH = \"E:/Data Science/Kaggle Competitions dataset/Hackerearth gala/dataset/Train Images/\"\n",
    "#for i in range(df.shape[0]):\n",
    "#    temp = PATH + str(df[\"Image\"][i])\n",
    "#    img = cv2.imread(temp)\n",
    "#    diff_shape.add(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "# resizing the image to the size of efficientnet\n",
    "IMG_WIDTH = 300\n",
    "IMG_HEIGHT = 300\n",
    "\n",
    "# Add Image augmentation to our generator\n",
    "train_datagen = ImageDataGenerator(rotation_range=90,\n",
    "                                   brightness_range=[0.2,1.0],\n",
    "                                   zoom_range=[0.5,1.0],\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True,\n",
    "                                   validation_split=0.1,\n",
    "                                   preprocessing_function=preprocess_image, \n",
    "                                   rescale=1 / 128.)\n",
    "train_generator = train_datagen.flow_from_dataframe(df, \n",
    "                                                    x_col='Image', \n",
    "                                                    y_col='Class',\n",
    "                                                    directory = PATH,\n",
    "                                                    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    class_mode='categorical', \n",
    "                                                    subset='training')\n",
    "val_generator = train_datagen.flow_from_dataframe(df, \n",
    "                                                  x_col='Image', \n",
    "                                                  y_col='Class',\n",
    "                                                  directory = PATH,\n",
    "                                                  target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "                                                  batch_size=BATCH_SIZE,\n",
    "                                                  class_mode='categorical',\n",
    "                                                  subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## seems like efficient net is too large\n",
    "# can try to freeze some layers\n",
    "\n",
    "\n",
    "from keras_efficientnets import EfficientNetB3\n",
    "effnet = EfficientNetB3(input_shape=(300,300,3),\n",
    "                        weights='imagenet',\n",
    "                        include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "l2 = l2(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "mc = ModelCheckpoint(r'E:\\Data Science\\Kaggle Competitions dataset\\Hackerearth gala\\dataset/efficientnetB3_Pure.h5', monitor='categorical_crossentropy', mode='min', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \"\"\"\n",
    "    A custom implementation of EfficientNetB5\n",
    "    for the APTOS 2019 competition\n",
    "    (Regression)\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(effnet)\n",
    "    \n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(4, activation=\"softmax\"))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=\"adam\", \n",
    "                  metrics=['categorical_crossentropy', 'mse'])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "# Initialize model\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='auto', verbose=1, patience=12)\n",
    "rlr = ReduceLROnPlateau(monitor='val_loss', \n",
    "                        factor=0.5, \n",
    "                        patience=5, \n",
    "                        verbose=1, \n",
    "                        mode='auto',\n",
    "                        epsilon=0.00001)\n",
    "\n",
    "# Begin training\n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "                    epochs=90,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps = val_generator.samples // BATCH_SIZE,\n",
    "                    callbacks=[mc, rlr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds_and_labels(model, generator):\n",
    "    \"\"\"\n",
    "    Get predictions and labels from the generator\n",
    "    \n",
    "    :param model: A Keras model object\n",
    "    :param generator: A Keras ImageDataGenerator object\n",
    "    \n",
    "    :return: A tuple with two Numpy Arrays. One containing the predictions\n",
    "    and one containing the labels\n",
    "    \"\"\"\n",
    "    preds = []\n",
    "    labels = []\n",
    "    for _ in range(int(np.ceil(generator.samples / BATCH_SIZE))):\n",
    "        print(_)\n",
    "        x, y = next(generator)\n",
    "        print(x,y)\n",
    "        preds.append(model.predict(x))\n",
    "        labels.append(y)\n",
    "    # Flatten list of numpy arrays\n",
    "    return np.concatenate(preds).ravel(), np.concatenate(labels).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"E:\\Data Science\\Kaggle Competitions dataset\\Hackerearth gala\\dataset\\Test Images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Class'] = np.zeros(df_test.shape[0])\n",
    "df_test[\"Class\"] = df_test[\"Class\"].apply(str)\n",
    "df_test[\"Class\"] = df_test[\"Class\"].astype(\"category\")\n",
    "# For preprocessing test images\n",
    "test_generator = ImageDataGenerator(preprocessing_function=preprocess_image, \n",
    "                                    rescale=1 / 128.).flow_from_dataframe(df_test,\n",
    "                                                                          x_col = \"Image\",\n",
    "                                                                          #y_col = \"Class\",\n",
    "                                                                          directory=test_path,\n",
    "                                                                          target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "                                                                          batch_size=1,\n",
    "                                                                          class_mode=None,\n",
    "                                                                          shuffle=False)\n",
    "filename = test_generator.filenames\n",
    "number_test = len(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = load_model('E:\\Data Science\\Kaggle Competitions dataset\\Hackerearth gala\\dataset/efficientnetB3_no_freezing.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = best_model.predict_generator(test_generator,number_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pred(pred):\n",
    "    output = []\n",
    "    output1 = []\n",
    "    for i in pred:\n",
    "        temp = max(i)\n",
    "        for c,j in enumerate(i):\n",
    "            if j == temp:\n",
    "                output1.append(c)\n",
    "    for i in output1:\n",
    "        if i==2:\n",
    "            output.append(\"Food\")\n",
    "        if i==3:\n",
    "            output.append(\"misc\")\n",
    "        if i==0:\n",
    "            output.append(\"Attire\")\n",
    "        if i==1:\n",
    "            output.append(\"Decorationandsignage\")\n",
    "    return output1,output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation,submission, = convert_pred(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop(\"Class\",axis =1)\n",
    "df_test[\"Class\"] = submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(\"E:\\Data Science\\Kaggle Competitions dataset\\Hackerearth gala\\dataset/submission.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "for i in range(df_test.shape[0]):\n",
    "    temp = test_path + str(df_test[\"Image\"][i])\n",
    "    print(df_test[\"Class\"][i])\n",
    "    img = cv2.imread(temp)\n",
    "    cv2.imshow('image',img)\n",
    "    cv2.waitKey(0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
