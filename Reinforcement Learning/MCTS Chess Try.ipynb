{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import chess\n",
    "from copy import copy\n",
    "import chess.svg\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from random import choice\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras model approach\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,BatchNormalization,Dense, Input\n",
    "from tensorflow.keras.activations import relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDING THE CODE SO THAT TENSORFLOW DOES NOT EAT THE WHOLE GPU MEMORY\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r n b q k b n r\n",
      "p p p p p p p p\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      ". . . . . . . .\n",
      "P P P P P P P P\n",
      "R N B Q K B N R\n",
      "rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = chess.Board()\n",
    "\n",
    "#b.push_san(\"e4\")\n",
    "print(b)\n",
    "print(b.fen())\n",
    "b.turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import gym\\nimport gym_chess\\nimport random\\n\\nenv = gym.make('Chess-v0')\\nprint(dir(env))\\nenv.reset()\\ndone = False\\n\\ncount = 0\\nwhile not done:\\n    print(env.render())\\n    print(env._board.fen())\\n    random.sample\\n    action = random.sample(env.legal_moves,1)\\n    a,b,done,d = env.step(action[0])\\n    state = copy(env)\\n    #count += 1\\n    #if count ==2:\\n    \\nenv.close()\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import gym\n",
    "import gym_chess\n",
    "import random\n",
    "\n",
    "env = gym.make('Chess-v0')\n",
    "print(dir(env))\n",
    "env.reset()\n",
    "done = False\n",
    "\n",
    "count = 0\n",
    "while not done:\n",
    "    print(env.render())\n",
    "    print(env._board.fen())\n",
    "    random.sample\n",
    "    action = random.sample(env.legal_moves,1)\n",
    "    a,b,done,d = env.step(action[0])\n",
    "    state = copy(env)\n",
    "    #count += 1\n",
    "    #if count ==2:\n",
    "    \n",
    "env.close()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(board):\n",
    "    '''\n",
    "    This is to encode a board position into the nn input\n",
    "    we will have 12 8*8 boards\n",
    "    first 6 will have the black pieces\n",
    "    next 6 will have the white pieces\n",
    "    \n",
    "    todo::::\n",
    "    \n",
    "    we can later include some cues for castling and special moves\n",
    "    \n",
    "    \n",
    "    \n",
    "    The order on both of them will be \n",
    "    \n",
    "    1 - pawn\n",
    "    2 - rook\n",
    "    3 - knights\n",
    "    4 - bishop\n",
    "    5 - queen\n",
    "    6 - king\n",
    "    \n",
    "    The final encoding will have the board reversed (we will see it through blacks perspective)\n",
    "    \n",
    "    '''\n",
    "    array = np.zeros((12, 8, 8), dtype=np.int) # these are the boards\n",
    "    \n",
    "    for square, piece in board.piece_map().items():\n",
    "        x = int(square/8)\n",
    "        y = int(square%8)\n",
    "\n",
    "        # this is the black piece encoding\n",
    "        \n",
    "        if piece.symbol() == \"p\":\n",
    "            array[0][x][y] = 1\n",
    "            \n",
    "        if piece.symbol() == \"r\":\n",
    "            array[1][x][y] = 1\n",
    "            \n",
    "        if piece.symbol() == \"n\":\n",
    "            array[2][x][y] = 1\n",
    "            \n",
    "        if piece.symbol() == \"b\":\n",
    "            array[3][x][y] = 1\n",
    "            \n",
    "        if piece.symbol() == \"q\":\n",
    "            array[4][x][y] = 1\n",
    "        \n",
    "        if piece.symbol() == \"k\":\n",
    "            array[5][x][y] = 1\n",
    "            \n",
    "        # This is the white piece encoding\n",
    "        \n",
    "        if piece.symbol() == \"P\":\n",
    "            array[6][x][y] = 1\n",
    "            \n",
    "        if piece.symbol() == \"R\":\n",
    "            array[7][x][y] = 1\n",
    "            \n",
    "        if piece.symbol() == \"N\":\n",
    "            array[8][x][y] = 1\n",
    "            \n",
    "        if piece.symbol() == \"B\":\n",
    "            array[9][x][y] = 1\n",
    "            \n",
    "        if piece.symbol() == \"Q\":\n",
    "            array[10][x][y] = 1\n",
    "            \n",
    "        if piece.symbol() == \"K\":\n",
    "            array[11][x][y] = 1\n",
    "    array.resize((8,8,12))\n",
    "    array = tf.expand_dims(array,0)\n",
    "    array = array.numpy()\n",
    "    array = np.array(array,dtype = \"float32\")\n",
    "    return array\n",
    "\n",
    "temp_encode = encode(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RL_Value_Function\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 8, 8, 12)]        0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 8, 8, 32)          3488      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 64)          18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 2, 2, 128)         204928    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 2, 2, 128)         409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 2, 2, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 1, 1, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 1, 1, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1, 1, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1000)              257000    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 3,841,985\n",
      "Trainable params: 3,835,025\n",
      "Non-trainable params: 6,960\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def model_keras():\n",
    "    \n",
    "    inputs = Input(shape=(8,8,12))\n",
    "    x = Conv2D(32,3, activation='relu',padding = \"same\",kernel_initializer=\"glorot_uniform\")(inputs)\n",
    "    x = Conv2D(32,3, activation='relu',padding = \"same\",kernel_initializer=\"glorot_uniform\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=None, padding=\"same\")(x)\n",
    "    \n",
    "    x = Conv2D(64,3, activation='relu',padding = \"same\",kernel_initializer=\"glorot_uniform\")(x)\n",
    "    x = Conv2D(64,3, activation='relu',padding = \"same\",kernel_initializer=\"glorot_uniform\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=None, padding=\"same\")(x)\n",
    "    \n",
    "    x = Conv2D(128,5, activation='relu',padding = \"same\",kernel_initializer=\"glorot_uniform\")(x)\n",
    "    x = Conv2D(128,5, activation='relu',padding = \"same\",kernel_initializer=\"glorot_uniform\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=None, padding=\"same\")(x)\n",
    "    \n",
    "    x = Conv2D(256,3, activation='relu',padding = \"same\",kernel_initializer=\"glorot_uniform\")(x)\n",
    "    x = Conv2D(256,3, activation='relu',padding = \"same\",kernel_initializer=\"glorot_uniform\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), strides=None, padding=\"same\")(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    x = Dense(1000,activation='relu',kernel_initializer=\"glorot_uniform\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(1000,activation='relu',kernel_initializer=\"glorot_uniform\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(1000,activation='relu',kernel_initializer=\"glorot_uniform\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    output = Dense(1,activation='sigmoid',kernel_initializer=\"glorot_uniform\")(x)\n",
    "    model = Model(inputs=inputs, outputs=output, name=\"RL_Value_Function\")\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    #model.compile(optimizer=\"adam\",loss='binary_crossentropy',metrics=['binary_crossentropy'])\n",
    "    \n",
    "    return model\n",
    "value_function = model_keras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_y_true(current_q,current_r,lamb):\n",
    "    return tf.math.multiply(current_q,lamb) + current_r\n",
    "def custom_loss(y_true,y_pred):\n",
    "    return tf.keras.losses.MSE(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step_keras(model,new_state,new_rew,old_q,lamb):\n",
    "    #print(\"input shape is \",inputs.shape)\n",
    "    \n",
    "    #outputs = np.array([outputs])\n",
    "    \n",
    "    #model.fit(x = inputs,y = outputs,batch_size = 1,epochs = 1)\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        # logits is the forward pass\n",
    "        logits = model(new_state, training=True)\n",
    "        \n",
    "        loss_value = custom_loss(create_y_true(logits,new_rew,lamb),old_q)\n",
    "    \n",
    "    #we retrieve the gradients\n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    \n",
    "    #THIS IS ONE STEP OF GRAD DESCENT (Minimizes the loss)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(20):\n",
    "#    train_step_keras(keras_model , temp_encode , 0 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from collections import defaultdict\n",
    "import math\n",
    "from copy import copy\n",
    "\n",
    "class MCTS:\n",
    "    \"Monte Carlo tree searcher. First rollout the tree then choose a move.\"\n",
    "\n",
    "    def __init__(self, exploration_weight=1):\n",
    "        self.Q = defaultdict(int)  # total reward of each node\n",
    "        self.N = defaultdict(int)  # total visit count for each node\n",
    "        self.children = dict()  # children of each node\n",
    "        self.exploration_weight = exploration_weight\n",
    "\n",
    "    def choose(self, node):\n",
    "        \"Choose the best successor of node. (Choose a move in the game)\"\n",
    "        if node.is_terminal():\n",
    "            raise RuntimeError(f\"choose called on terminal node {node}\")\n",
    "\n",
    "        if node not in self.children:\n",
    "            return node.find_random_child()\n",
    "\n",
    "        def score(n):\n",
    "            if self.N[n] == 0:\n",
    "                return float(\"-inf\")  # avoid unseen moves\n",
    "            return self.Q[n] / self.N[n]  # average reward\n",
    "\n",
    "        return max(self.children[node], key=score)\n",
    "\n",
    "    def do_rollout(self, node):\n",
    "        \"Make the tree one layer better. (Train for one iteration.)\"\n",
    "\n",
    "        path = self._select(node)\n",
    "\n",
    "        leaf = path[-1]\n",
    "        self._expand(leaf)\n",
    "        \n",
    "        reward = self._simulate(leaf)\n",
    "        self._backpropagate(path, reward)\n",
    "\n",
    "        \n",
    "    def _select(self, node):\n",
    "        \"Find an unexplored descendent of `node`\"\n",
    "        path = []\n",
    "\n",
    "        while True:\n",
    "            path.append(node)\n",
    "            if node not in self.children:\n",
    "                # node is either unexplored or terminal\n",
    "                return path\n",
    "            unexplored = self.children[node] - self.children.keys()\n",
    "            \n",
    "\n",
    "            \n",
    "            if unexplored:\n",
    "                n = unexplored.pop()\n",
    "                path.append(n)\n",
    "                return path\n",
    "            node = self._uct_select(node)  # descend a layer deeper\n",
    "\n",
    "    def _expand(self, node):\n",
    "        \"Update the `children` dict with the children of `node`\"\n",
    "        if node in self.children:\n",
    "            return  # already expanded\n",
    "        self.children[node] = node.find_children()\n",
    "\n",
    "    def _simulate(self, node):\n",
    "\n",
    "        ''' This simulates the current position for upto n moves and then uses \n",
    "            the value function to see what the expected reward might be and then\n",
    "            returns the reward\n",
    "            \n",
    "            This also updates the nn for each state as we have the perfect chess model\n",
    "            and know the reward for each state\n",
    "        \n",
    "        '''\n",
    "        reward = None\n",
    "        \n",
    "        for i in range(20):  \n",
    "            if node.is_terminal():\n",
    "                reward = node.reward()\n",
    "                return reward\n",
    "            prev_q = value_function(encode(node.position),training = False)[0][0]\n",
    "            \n",
    "            node = node.find_random_child()\n",
    "            reward = value_function(encode(node.position))[0][0]\n",
    "            #train_step_keras(value_function,encode(node.position),reward,prev_q,0.95)\n",
    "            \n",
    "        return reward\n",
    "    \n",
    "    def _backpropagate(self, path, reward):\n",
    "        \"Send the reward back up to the ancestors of the leaf\"\n",
    "        for node in reversed(path):\n",
    "            self.N[node] += 1\n",
    "            self.Q[node] += reward\n",
    "            reward = reward\n",
    "\n",
    "    def _uct_select(self, node):\n",
    "        \"Select a child of node, balancing exploration & exploitation\"\n",
    "\n",
    "        # All children of node should already be expanded:\n",
    "        assert all(n in self.children for n in self.children[node])\n",
    "\n",
    "        log_N_vertex = math.log(self.N[node])\n",
    "\n",
    "        def uct(n):\n",
    "            \"Upper confidence bound for trees\"\n",
    "            return self.Q[n] / self.N[n] + self.exploration_weight * math.sqrt(\n",
    "                log_N_vertex / self.N[n]\n",
    "            )\n",
    "\n",
    "        return max(self.children[node], key=uct)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Node(ABC):\n",
    "    \"\"\"\n",
    "    A representation of a single board state.\n",
    "    MCTS works by constructing a tree of these Nodes.\n",
    "    Could be e.g. a chess or checkers board state.\n",
    "    \"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def find_children(self):\n",
    "        \"All possible successors of this board state\"\n",
    "        \n",
    "        '''basically if there a move and the game is not over then return\n",
    "        all possible board positions and not just all possible moves.\n",
    "        '''\n",
    "\n",
    "    @abstractmethod\n",
    "    def find_random_child(self):\n",
    "        \"Random successor of this board state (for more efficient simulation)\"\n",
    "        return None\n",
    "\n",
    "    @abstractmethod\n",
    "    def is_terminal(self):\n",
    "        \"Returns True if the node has no children\"\n",
    "        return True\n",
    "\n",
    "    @abstractmethod\n",
    "    def reward(self):\n",
    "        \"Assumes `self` is terminal node. 1=win, 0=loss, .5=tie, etc\"\n",
    "        return 0\n",
    "\n",
    "    \n",
    "class ChessBoard(Node):\n",
    "    move = []\n",
    "    reward = []\n",
    "    def __init__(self,board):\n",
    "        self.position = board\n",
    "        self.curr_reward = 0\n",
    "        \n",
    "    def find_children(board):\n",
    "        if board.position.result() != \"*\":  # If the game is finished then no moves can be made\n",
    "\n",
    "            return []\n",
    "        \n",
    "        all_next_states = []\n",
    "        temp_fen = board.position.fen()\n",
    "        for i in board.position.legal_moves:\n",
    "            \n",
    "            board_copy = copy(board)\n",
    "            board_copy.position.set_fen(temp_fen)\n",
    "            \n",
    "            all_next_states.append(board_copy.make_move(board_copy,i))\n",
    "\n",
    "        return all_next_states\n",
    "        \n",
    "    def make_move(self,board1, move):\n",
    "        board1.position.push(move)\n",
    "        return board\n",
    "    \n",
    "    def find_random_child(board):\n",
    "        '''Random successor of this board state (for more efficient simulation)\n",
    "        \n",
    "        Need a NN named value_function\n",
    "        and a function encode which converts the board state into the nn format\n",
    "        '''\n",
    "        \n",
    "        if board.position.result() != \"*\":\n",
    "            return None\n",
    "        else:\n",
    "            current_next_states = []\n",
    "            current_board_values = []\n",
    "            max_val = -1000\n",
    "            max_index = None\n",
    "            min_val = 100000\n",
    "            legal = list(board.position.legal_moves)\n",
    "            temp_fen = board.position.fen()\n",
    "            for c,i in enumerate(legal):\n",
    "            # generate a copy of the current board\n",
    "                board_copy = copy(board)\n",
    "                board_copy.position.set_fen(temp_fen)\n",
    "                \n",
    "                current_next_states.append(board_copy.make_move(board_copy,i).position)\n",
    "                temp = value_function(encode(board_copy.position),training = False)[0][0]\n",
    "                current_board_values.append(temp)\n",
    "                if temp>max_val:\n",
    "                    max_val = temp\n",
    "                    max_index = c\n",
    "                if temp<min_val:\n",
    "                    min_index = c\n",
    "            # 10 % exploration chance\n",
    "            if random.randint(0,9) == 0:\n",
    "                board_copy = copy(board)\n",
    "                board_copy.position.set_fen(temp_fen)\n",
    "                return board_copy.make_move(board_copy,random.sample(legal,1)[0])\n",
    "            else:\n",
    "                # 90 % time we choose the best move in SIMULATIONS (this is the simulation policy wrt the value function)\n",
    "                board_copy = copy(board)\n",
    "                board_copy.position.set_fen(temp_fen)\n",
    "                # return best move for white\n",
    "                if board_copy.position.turn == True:    \n",
    "                    return board_copy.make_move(board_copy,legal[max_index])\n",
    "                else:\n",
    "                    # return best move for black\n",
    "                    return board_copy.make_move(board_copy,legal[min_index])\n",
    "            \n",
    "    def is_terminal(board):\n",
    "        if board.position.result() == \"*\":\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    def reward(board):\n",
    "        if board.position.result() == \"*\":\n",
    "            return 0\n",
    "        elif board.position.result() == \"0-1\":\n",
    "            return -1\n",
    "        elif board.position.result() == \"1-0\":\n",
    "            return 1\n",
    "        elif board.position.result() == \"1/2-1/2\":\n",
    "            return 0.5\n",
    "        else:\n",
    "            print(board.position.result())\n",
    "            return board.position.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THIS MCTS IS WRONGG as the implementation of Chessboard node is INCORRECT\n",
    "## EACH BOARD IN THE CHILDREN LIST SHOULD BE A CHESSBOARD OBJECT AND NOT A BOARD STATE OBJECT NEED TO FIX THIS ASAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [05:02<07:22,  7.50s/it]ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ishtd\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-14-d6d27686dc64>\", line 35, in <module>\n",
      "    tree.do_rollout(board_copy)\n",
      "  File \"<ipython-input-12-437ca8f753e1>\", line 38, in do_rollout\n",
      "    reward = self._simulate(leaf)\n",
      "  File \"<ipython-input-12-437ca8f753e1>\", line 85, in _simulate\n",
      "    node = node.find_random_child()\n",
      "  File \"<ipython-input-13-ce6e48395522>\", line 82, in find_random_child\n",
      "    temp = value_function(encode(board_copy.position),training = False)[0][0]\n",
      "  File \"<ipython-input-6-bd1b20fffe0c>\", line 72, in encode\n",
      "    array = tf.expand_dims(array,0)\n",
      "  File \"C:\\Users\\ishtd\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow_core\\python\\util\\dispatch.py\", line 180, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"C:\\Users\\ishtd\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\", line 325, in expand_dims_v2\n",
      "    return gen_array_ops.expand_dims(input, axis, name)\n",
      "  File \"C:\\Users\\ishtd\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py\", line 2449, in expand_dims\n",
      "    \"ExpandDims\", name, _ctx._post_execution_callbacks, input, axis)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ishtd\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ishtd\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\ishtd\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\ishtd\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\ishtd\\Anaconda3\\envs\\deeplearning\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\ishtd\\Anaconda3\\envs\\deeplearning\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\ishtd\\Anaconda3\\envs\\deeplearning\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\ishtd\\Anaconda3\\envs\\deeplearning\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"C:\\Users\\ishtd\\Anaconda3\\envs\\deeplearning\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\Users\\ishtd\\Anaconda3\\envs\\deeplearning\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\Users\\ishtd\\Anaconda3\\envs\\deeplearning\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-d6d27686dc64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mboard_copy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_fen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_fen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m             \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_rollout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard_copy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-437ca8f753e1>\u001b[0m in \u001b[0;36mdo_rollout\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_simulate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleaf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backpropagate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-437ca8f753e1>\u001b[0m in \u001b[0;36m_simulate\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m             \u001b[0mnode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_random_child\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m             \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-ce6e48395522>\u001b[0m in \u001b[0;36mfind_random_child\u001b[1;34m(board)\u001b[0m\n\u001b[0;32m     81\u001b[0m                 \u001b[0mcurrent_next_states\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard_copy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard_copy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m                 \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard_copy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m                 \u001b[0mcurrent_board_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-bd1b20fffe0c>\u001b[0m in \u001b[0;36mencode\u001b[1;34m(board)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow_core\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mexpand_dims_v2\u001b[1;34m(input, axis, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m   \"\"\"\n\u001b[1;32m--> 325\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mexpand_dims\u001b[1;34m(input, axis, name)\u001b[0m\n\u001b[0;32m   2448\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2449\u001b[1;33m         \"ExpandDims\", name, _ctx._post_execution_callbacks, input, axis)\n\u001b[0m\u001b[0;32m   2450\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2043\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2044\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2045\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2045\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2046\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[1;32m-> 2047\u001b[1;33m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[0;32m   2048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2049\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[1;32m-> 1436\u001b[1;33m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[0;32m   1437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1334\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[1;32m-> 1336\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1337\u001b[0m             )\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Minimal'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[1;32m-> 1193\u001b[1;33m                                                                tb_offset)\n\u001b[0m\u001b[0;32m   1194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[1;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1150\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "# SELF PLAY\n",
    "#%%time\n",
    "#%%svg\n",
    "\n",
    "def calculate_reward(board):\n",
    "    if board.position.result() == \"*\":\n",
    "        return 0\n",
    "    elif board.position.result() == \"0-1\":\n",
    "        return -1\n",
    "    elif board.position.result() == \"1-0\":\n",
    "        return 1\n",
    "    elif board.position.result() == \"1/2-1/2\":\n",
    "        return 0.5\n",
    "\n",
    "current_state = []\n",
    "next_state = []\n",
    "reward_replay = []\n",
    "game_no = []\n",
    "moves = 0\n",
    "for i in range(1):\n",
    "    temp_board = chess.Board()\n",
    "    board = ChessBoard(temp_board)\n",
    "    done = False\n",
    "    while not done:\n",
    "        tree = MCTS()\n",
    "        temp_fen = board.position.fen()\n",
    "        current_state.append(temp_fen)\n",
    "        board_copy = copy(board)\n",
    "        board_copy.position.set_fen(temp_fen)\n",
    "        prev_q = value_function(encode(board_copy.position),training = False)[0][0]\n",
    "        \n",
    "        for j in tqdm(range(100)):\n",
    "            board_copy = copy(board)\n",
    "            board_copy.position.set_fen(temp_fen)\n",
    "            tree.do_rollout(board_copy)\n",
    "            \n",
    "        board_copy = copy(board)\n",
    "        board_copy.position.set_fen(temp_fen)\n",
    "        print(\"THE CHOSEN MOVE\")\n",
    "        current_position = tree.choose(board_copy).position\n",
    "        next_state.append(current_position.fen())\n",
    "        print(current_position)\n",
    "        reward = calculate_reward(board)\n",
    "        reward_replay.append(reward)\n",
    "        print(reward)\n",
    "        game_no.append(i)\n",
    "        train_step_keras(value_function,encode(current_position),reward,prev_q,0.95)\n",
    "        \n",
    "        moves = moves + 1\n",
    "        \n",
    "        if board.position.result() != \"*\":\n",
    "            print(board.position.result())\n",
    "            done = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TURN BASED MOVES\n",
    "#%%time\n",
    "import chess\n",
    "from random import choice\n",
    "def calculate_reward(board):\n",
    "    if board.position.result() == \"*\":\n",
    "        return 0\n",
    "    elif board.position.result() == \"0-1\":\n",
    "        return -1\n",
    "    elif board.position.result() == \"1-0\":\n",
    "        return 1\n",
    "    elif board.position.result() == \"1/2-1/2\":\n",
    "        return 0.5\n",
    "moves = 0\n",
    "for i in range(1):\n",
    "    temp_board = chess.Board()\n",
    "    board = ChessBoard(temp_board)\n",
    "    done = False\n",
    "    turn = 0\n",
    "    while not done:\n",
    "        if turn == 0:\n",
    "            tree = MCTS()\n",
    "            temp_fen = board.position.fen()\n",
    "            for j in tqdm(range(500)):\n",
    "                board_copy = copy(board)\n",
    "                board_copy.position.set_fen(temp_fen)\n",
    "                tree.do_rollout(board_copy)\n",
    "\n",
    "            board_copy = copy(board)\n",
    "            board_copy.position.set_fen(temp_fen)\n",
    "            print(\"THE CHOSEN MOVE\")\n",
    "            print(tree.choose(board_copy).position)\n",
    "            chess.svg.board(board_copy)\n",
    "            reward = calculate_reward(board)\n",
    "            print(reward)\n",
    "            moves = moves + 1\n",
    "            turn = 1\n",
    "            if board.position.result() != \"*\":\n",
    "                print(board.position.result())\n",
    "                done = True\n",
    "        if turn == 1:\n",
    "            player_move = input(\"ENTER THE MOVE THAT YOU WOULD LIKE TO PLAY : \")\n",
    "            player_move = chess.Move.from_uci(player_move)\n",
    "            \n",
    "            board.position.push(player_move)\n",
    "            print(\"The player moved : \")\n",
    "            print(board.position)\n",
    "            turn = 0\n",
    "            if board.position.result() != \"*\":\n",
    "                print(board.position.result())\n",
    "                done = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
