{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import gym\n",
    "import pylab\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "\n",
    "EPISODES = 300\n",
    "\n",
    "\n",
    "# DQN Agent for the Cartpole\n",
    "# it uses Neural Network to approximate q function\n",
    "# and replay memory & target q network\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        # if you want to see Cartpole learning, then change to True\n",
    "        self.render = False\n",
    "        self.load_model = False\n",
    "\n",
    "        # get size of state and action\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        # These are hyper parameters for the DQN\n",
    "        self.discount_factor = 0.99\n",
    "        self.learning_rate = 0.001\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_decay = 0.999\n",
    "        self.epsilon_min = 0.01\n",
    "        self.batch_size = 64\n",
    "        self.train_start = 1000\n",
    "        # create replay memory using deque\n",
    "        self.memory = deque(maxlen=2000)\n",
    "\n",
    "        # create main model and target model\n",
    "        self.model = self.build_model()\n",
    "        self.target_model = self.build_model()\n",
    "\n",
    "        # initialize target model\n",
    "        self.update_target_model()\n",
    "\n",
    "        if self.load_model:\n",
    "            self.model.load_weights(\"./save_model/cartpole_dqn.h5\")\n",
    "\n",
    "    # approximate Q function using Neural Network\n",
    "    # state is input and Q Value of each action is output of network\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim=self.state_size, activation='relu',\n",
    "                        kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(24, activation='relu',\n",
    "                        kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(self.action_size, activation='linear',\n",
    "                        kernel_initializer='he_uniform'))\n",
    "        model.summary()\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    # after some time interval update the target model to be same with model\n",
    "    def update_target_model(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "    # get action from model using epsilon-greedy policy\n",
    "    def get_action(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        else:\n",
    "            q_value = self.model.predict(state)\n",
    "            return np.argmax(q_value[0])\n",
    "\n",
    "    # save sample <s,a,r,s'> to the replay memory\n",
    "    def append_sample(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "    # pick samples randomly from replay memory (with batch_size)\n",
    "    def train_model(self):\n",
    "        if len(self.memory) < self.train_start:\n",
    "            return\n",
    "        batch_size = min(self.batch_size, len(self.memory))\n",
    "        mini_batch = random.sample(self.memory, batch_size)\n",
    "\n",
    "        update_input = np.zeros((batch_size, self.state_size))\n",
    "        update_target = np.zeros((batch_size, self.state_size))\n",
    "        action, reward, done = [], [], []\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            update_input[i] = mini_batch[i][0]\n",
    "            action.append(mini_batch[i][1])\n",
    "            reward.append(mini_batch[i][2])\n",
    "            update_target[i] = mini_batch[i][3]\n",
    "            done.append(mini_batch[i][4])\n",
    "\n",
    "        target = self.model.predict(update_input)\n",
    "        target_val = self.target_model.predict(update_target)\n",
    "\n",
    "        for i in range(self.batch_size):\n",
    "            # Q Learning: get maximum Q value at s' from target model\n",
    "            if done[i]:\n",
    "                target[i][action[i]] = reward[i]\n",
    "            else:\n",
    "                target[i][action[i]] = reward[i] + self.discount_factor * (\n",
    "                    np.amax(target_val[i]))\n",
    "\n",
    "        # and do the model fit!\n",
    "        self.model.fit(update_input, target, batch_size=self.batch_size,\n",
    "                       epochs=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 24)                120       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 50        \n",
      "=================================================================\n",
      "Total params: 770\n",
      "Trainable params: 770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 24)                120       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 24)                600       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 50        \n",
      "=================================================================\n",
      "Total params: 770\n",
      "Trainable params: 770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "episode: 0   score: 15.0   memory length: 16   epsilon: 0.98411944181564\n",
      "episode: 1   score: 15.0   memory length: 32   epsilon: 0.9684910757595269\n",
      "episode: 2   score: 41.0   memory length: 74   epsilon: 0.9286373107007023\n",
      "episode: 3   score: 11.0   memory length: 86   epsilon: 0.9175547491935327\n",
      "episode: 4   score: 10.0   memory length: 97   epsilon: 0.9075119613694457\n",
      "episode: 5   score: 14.0   memory length: 112   epsilon: 0.8939941590229386\n",
      "episode: 6   score: 38.0   memory length: 151   epsilon: 0.8597827393003539\n",
      "episode: 7   score: 11.0   memory length: 163   epsilon: 0.8495219033622532\n",
      "episode: 8   score: 13.0   memory length: 177   epsilon: 0.8377055948310879\n",
      "episode: 9   score: 10.0   memory length: 188   epsilon: 0.8285367691502946\n",
      "episode: 10   score: 12.0   memory length: 201   epsilon: 0.8178301806491574\n",
      "episode: 11   score: 18.0   memory length: 220   epsilon: 0.8024304668606914\n",
      "episode: 12   score: 15.0   memory length: 236   epsilon: 0.7896874231428072\n",
      "episode: 13   score: 13.0   memory length: 250   epsilon: 0.7787033741169904\n",
      "episode: 14   score: 12.0   memory length: 263   epsilon: 0.7686407469632577\n",
      "episode: 15   score: 13.0   memory length: 277   epsilon: 0.7579494437963867\n",
      "episode: 16   score: 18.0   memory length: 296   epsilon: 0.7436772821951526\n",
      "episode: 17   score: 9.0   memory length: 306   epsilon: 0.7362738857656108\n",
      "episode: 18   score: 14.0   memory length: 321   epsilon: 0.7253067522353204\n",
      "episode: 19   score: 10.0   memory length: 332   epsilon: 0.7173681503955072\n",
      "episode: 20   score: 19.0   memory length: 352   epsilon: 0.7031562730010349\n",
      "episode: 21   score: 33.0   memory length: 386   epsilon: 0.6796392551158754\n",
      "episode: 22   score: 14.0   memory length: 401   epsilon: 0.6695157201007336\n",
      "episode: 23   score: 10.0   memory length: 412   epsilon: 0.6621877602947683\n",
      "episode: 24   score: 16.0   memory length: 429   epsilon: 0.6510201771893979\n",
      "episode: 25   score: 12.0   memory length: 442   epsilon: 0.6426075087326283\n",
      "episode: 26   score: 16.0   memory length: 459   epsilon: 0.6317701402576925\n",
      "episode: 27   score: 8.0   memory length: 468   epsilon: 0.6261068997312542\n",
      "episode: 28   score: 11.0   memory length: 480   epsilon: 0.6186348025557711\n",
      "episode: 29   score: 17.0   memory length: 498   epsilon: 0.6075935243162931\n",
      "episode: 30   score: 37.0   memory length: 536   epsilon: 0.5849270275271061\n",
      "episode: 31   score: 9.0   memory length: 546   epsilon: 0.5791040088995179\n",
      "episode: 32   score: 10.0   memory length: 557   epsilon: 0.572765620160788\n",
      "episode: 33   score: 28.0   memory length: 586   epsilon: 0.5563858806683429\n",
      "episode: 34   score: 16.0   memory length: 603   epsilon: 0.5470026121551156\n",
      "episode: 35   score: 13.0   memory length: 617   epsilon: 0.5393941542601555\n",
      "episode: 36   score: 17.0   memory length: 635   epsilon: 0.5297671482893791\n",
      "episode: 37   score: 10.0   memory length: 646   epsilon: 0.5239687596143511\n",
      "episode: 38   score: 12.0   memory length: 659   epsilon: 0.5171978858215134\n",
      "episode: 39   score: 9.0   memory length: 669   epsilon: 0.5120491189128954\n",
      "episode: 40   score: 18.0   memory length: 688   epsilon: 0.5024072518560504\n",
      "episode: 41   score: 13.0   memory length: 702   epsilon: 0.49541908701565013\n",
      "episode: 42   score: 10.0   memory length: 713   epsilon: 0.4899966435273741\n",
      "episode: 43   score: 11.0   memory length: 725   epsilon: 0.4841489160264175\n",
      "episode: 44   score: 11.0   memory length: 737   epsilon: 0.47837097658906735\n",
      "episode: 45   score: 9.0   memory length: 747   epsilon: 0.47360873621294336\n",
      "episode: 46   score: 14.0   memory length: 762   epsilon: 0.4665541192401326\n",
      "episode: 47   score: 9.0   memory length: 772   epsilon: 0.4619095170944617\n",
      "episode: 48   score: 13.0   memory length: 786   epsilon: 0.45548464994757865\n",
      "episode: 49   score: 9.0   memory length: 796   epsilon: 0.45095024569472963\n",
      "episode: 50   score: 12.0   memory length: 809   epsilon: 0.4451229379699419\n",
      "episode: 51   score: 10.0   memory length: 820   epsilon: 0.4402509941152613\n",
      "episode: 52   score: 27.0   memory length: 848   epsilon: 0.42808894786458934\n",
      "episode: 53   score: 13.0   memory length: 862   epsilon: 0.42213450329202495\n",
      "episode: 54   score: 11.0   memory length: 874   epsilon: 0.41709665746876984\n",
      "episode: 55   score: 9.0   memory length: 884   epsilon: 0.4129444102795546\n",
      "episode: 56   score: 15.0   memory length: 900   epsilon: 0.4063866225452039\n",
      "episode: 57   score: 21.0   memory length: 922   epsilon: 0.39753936928566525\n",
      "episode: 58   score: 15.0   memory length: 938   epsilon: 0.39122622220115044\n",
      "episode: 59   score: 7.0   memory length: 946   epsilon: 0.3881073448764583\n",
      "episode: 60   score: 36.0   memory length: 983   epsilon: 0.37400286247792053\n",
      "episode: 61   score: 11.0   memory length: 995   epsilon: 0.36953943022131486\n",
      "episode: 62   score: 10.0   memory length: 1006   epsilon: 0.3654947603053141\n",
      "episode: 63   score: 9.0   memory length: 1016   epsilon: 0.36185621618376534\n",
      "episode: 64   score: 30.0   memory length: 1047   epsilon: 0.3508053214034905\n",
      "episode: 65   score: 19.0   memory length: 1067   epsilon: 0.34385546976264747\n",
      "episode: 66   score: 18.0   memory length: 1086   epsilon: 0.33738068325533116\n",
      "episode: 67   score: 106.0   memory length: 1193   epsilon: 0.3031289768215478\n",
      "episode: 68   score: 64.0   memory length: 1258   epsilon: 0.2840430636776882\n",
      "episode: 69   score: 22.0   memory length: 1281   epsilon: 0.27758143557361825\n",
      "episode: 70   score: 9.0   memory length: 1291   epsilon: 0.27481807913093287\n",
      "episode: 71   score: 9.0   memory length: 1301   epsilon: 0.2720822322326576\n",
      "episode: 72   score: 10.0   memory length: 1312   epsilon: 0.26910424739696437\n",
      "episode: 73   score: 10.0   memory length: 1323   epsilon: 0.266158857095684\n",
      "episode: 74   score: 27.0   memory length: 1351   epsilon: 0.2588061506321157\n",
      "episode: 75   score: 66.0   memory length: 1418   epsilon: 0.24202615672604952\n",
      "episode: 76   score: 47.0   memory length: 1466   epsilon: 0.23067776730555875\n",
      "episode: 77   score: 107.0   memory length: 1574   epsilon: 0.20705154127145922\n",
      "episode: 78   score: 97.0   memory length: 1672   epsilon: 0.1877138485735047\n",
      "episode: 79   score: 54.0   memory length: 1727   epsilon: 0.1776634806674152\n",
      "episode: 80   score: 53.0   memory length: 1781   epsilon: 0.16831953801618357\n",
      "episode: 81   score: 205.0   memory length: 1987   epsilon: 0.1369698893837471\n",
      "episode: 82   score: 413.0   memory length: 2000   epsilon: 0.09051847541007228\n",
      "episode: 83   score: 488.0   memory length: 2000   epsilon: 0.05549590947736964\n",
      "episode: 84   score: 432.0   memory length: 2000   epsilon: 0.03598465762322022\n",
      "episode: 85   score: 500.0   memory length: 2000   epsilon: 0.021820338720759277\n",
      "episode: 86   score: 500.0   memory length: 2000   epsilon: 0.013231393970007657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 87   score: 299.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 88   score: 500.0   memory length: 2000   epsilon: 0.009998671593271896\n",
      "episode: 89   score: 418.0   memory length: 2000   epsilon: 0.009998671593271896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ishtd\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-2-1d1ccd616461>\", line 31, in <module>\n",
      "    agent.train_model()\n",
      "  File \"<ipython-input-1-9b8e0d0adf2e>\", line 111, in train_model\n",
      "    epochs=1, verbose=0)\n",
      "  File \"C:\\Users\\ishtd\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\training.py\", line 1239, in fit\n",
      "    validation_freq=validation_freq)\n",
      "  File \"C:\\Users\\ishtd\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\training_arrays.py\", line 196, in fit_loop\n",
      "    outs = fit_function(ins_batch)\n",
      "  File \"C:\\Users\\ishtd\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3740, in __call__\n",
      "    outputs = self._graph_fn(*converted_inputs)\n",
      "  File \"C:\\Users\\ishtd\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1081, in __call__\n",
      "    return self._call_impl(args, kwargs)\n",
      "  File \"C:\\Users\\ishtd\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1121, in _call_impl\n",
      "    return self._call_flat(args, self.captured_inputs, cancellation_manager)\n",
      "  File \"C:\\Users\\ishtd\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1224, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager)\n",
      "  File \"C:\\Users\\ishtd\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 511, in call\n",
      "    ctx=ctx)\n",
      "  File \"C:\\Users\\ishtd\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\", line 61, in quick_execute\n",
      "    num_outputs)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ishtd\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ishtd\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\ishtd\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\ishtd\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\ishtd\\Anaconda3\\envs\\deeplearning\\lib\\inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\ishtd\\Anaconda3\\envs\\deeplearning\\lib\\inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\ishtd\\Anaconda3\\envs\\deeplearning\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\ishtd\\Anaconda3\\envs\\deeplearning\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"C:\\Users\\ishtd\\Anaconda3\\envs\\deeplearning\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\Users\\ishtd\\Anaconda3\\envs\\deeplearning\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\Users\\ishtd\\Anaconda3\\envs\\deeplearning\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-1d1ccd616461>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;31m# every time step do the training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-9b8e0d0adf2e>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m         self.model.fit(update_input, target, batch_size=self.batch_size,\n\u001b[1;32m--> 111\u001b[1;33m                        epochs=1, verbose=0)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2043\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2044\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2045\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2045\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2046\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[1;32m-> 2047\u001b[1;33m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[0;32m   2048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2049\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[1;32m-> 1436\u001b[1;33m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[0;32m   1437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1334\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[1;32m-> 1336\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1337\u001b[0m             )\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Minimal'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[1;32m-> 1193\u001b[1;33m                                                                tb_offset)\n\u001b[0m\u001b[0;32m   1194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[1;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1150\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function flush_figures at 0x000001E04B40A2F0> (for post_execute):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\ipykernel\\pylab\\backend_inline.py\u001b[0m in \u001b[0;36mflush_figures\u001b[1;34m()\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;31m# ignore the tracking, just draw and close all figures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[1;31m# safely show traceback if in IPython, else raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\ipykernel\\pylab\\backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(close, block)\u001b[0m\n\u001b[0;32m     41\u001b[0m             display(\n\u001b[0;32m     42\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m                 \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m             )\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36mdisplay\u001b[1;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m             \u001b[0mformat_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m                 \u001b[1;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36mformat\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m                 \u001b[1;31m# FIXME: log the exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[1;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[1;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    339\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m             \u001b[1;31m# Finally look for special method names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(fig)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'png'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m         \u001b[0mpng_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'png'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'retina'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'png2x'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[0mFigureCanvasBase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'svg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[0;32m   2065\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bbox_extra_artists\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2066\u001b[0m                     bbox_inches = self.figure.get_tightbbox(renderer,\n\u001b[1;32m-> 2067\u001b[1;33m                             bbox_extra_artists=bbox_artists)\n\u001b[0m\u001b[0;32m   2068\u001b[0m                     \u001b[0mpad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pad_inches\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2069\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mpad\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[1;34m(self, renderer, bbox_extra_artists)\u001b[0m\n\u001b[0;32m   2365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2366\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2367\u001b[1;33m             \u001b[0mbbox\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2368\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbbox\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mbbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2369\u001b[0m                 \u001b[0mbb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[1;34m(self, renderer, call_axes_locator, bbox_extra_artists)\u001b[0m\n\u001b[0;32m   4355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4356\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxison\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4357\u001b[1;33m             \u001b[0mbb_xaxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4358\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbb_xaxis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4359\u001b[0m                 \u001b[0mbb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbb_xaxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   1160\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1162\u001b[1;33m         \u001b[0mticks_to_draw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1164\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_label_position\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36m_update_ticks\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1077\u001b[0m         \u001b[0mthe\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m  \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mticks\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mdrawn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m         \"\"\"\n\u001b[1;32m-> 1079\u001b[1;33m         \u001b[0mmajor_locs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_majorticklocs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1080\u001b[0m         \u001b[0mmajor_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_ticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmajor_locs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m         \u001b[0mmajor_ticks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_major_ticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmajor_locs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36mget_majorticklocs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_majorticklocs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m         \u001b[1;34m\"\"\"Get the array of major tick locations in data coordinates.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1324\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_minorticklocs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\ticker.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2079\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2080\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_view_interval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2081\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtick_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2083\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtick_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\ticker.py\u001b[0m in \u001b[0;36mtick_values\u001b[1;34m(self, vmin, vmax)\u001b[0m\n\u001b[0;32m   2087\u001b[0m         vmin, vmax = mtransforms.nonsingular(\n\u001b[0;32m   2088\u001b[0m             vmin, vmax, expander=1e-13, tiny=1e-14)\n\u001b[1;32m-> 2089\u001b[1;33m         \u001b[0mlocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raw_ticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2091\u001b[0m         \u001b[0mprune\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prune\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\ticker.py\u001b[0m in \u001b[0;36m_raw_ticks\u001b[1;34m(self, vmin, vmax)\u001b[0m\n\u001b[0;32m   2026\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nbins\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'auto'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2027\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2028\u001b[1;33m                 nbins = np.clip(self.axis.get_tick_space(),\n\u001b[0m\u001b[0;32m   2029\u001b[0m                                 max(1, self._min_n_ticks - 1), 9)\n\u001b[0;32m   2030\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36mget_tick_space\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2181\u001b[0m         \u001b[0mends\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransAxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2182\u001b[0m         \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mends\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mends\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m72\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2183\u001b[1;33m         \u001b[0mtick\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2184\u001b[0m         \u001b[1;31m# There is a heuristic here that the aspect ratio of tick text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2185\u001b[0m         \u001b[1;31m# is no more than 3:1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36m_get_tick\u001b[1;34m(self, major)\u001b[0m\n\u001b[0;32m   1931\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1932\u001b[0m             \u001b[0mtick_kw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_minor_tick_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1933\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mXTick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmajor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmajor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtick_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1934\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1935\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, axes, loc, label, size, width, color, tickdir, pad, labelsize, labelcolor, zorder, gridOn, tick1On, tick2On, label1On, label2On, major, labelrotation, grid_color, grid_linestyle, grid_linewidth, grid_alpha, **kw)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_tickdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtickdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtick1line\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tick1line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtick2line\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tick2line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgridline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_gridline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36m_get_tick1line\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    462\u001b[0m                           \u001b[0mlinestyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'None'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tickmarkers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m                           \u001b[0mmarkersize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m                           markeredgewidth=self._width, zorder=self._zorder)\n\u001b[0m\u001b[0;32m    465\u001b[0m         \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_xaxis_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwhich\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tick1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_artist_props\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\lines.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, xdata, ydata, linewidth, linestyle, color, marker, markersize, markeredgewidth, markeredgecolor, markerfacecolor, markerfacecoloralt, fillstyle, antialiased, dash_capstyle, solid_capstyle, dash_joinstyle, solid_joinstyle, pickradius, drawstyle, markevery, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_color\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_marker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMarkerStyle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmarker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfillstyle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_markevery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\markers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, marker, fillstyle)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_marker_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_fillstyle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfillstyle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_marker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmarker\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_recache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\markers.py\u001b[0m in \u001b[0;36mset_marker\u001b[1;34m(self, marker)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_marker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmarker\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_recache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\markers.py\u001b[0m in \u001b[0;36m_recache\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_capstyle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'butt'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_marker_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\markers.py\u001b[0m in \u001b[0;36m_set_tickdown\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    767\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_tickdown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 769\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAffine2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    770\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_snap_threshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    771\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\transforms.py\u001b[0m in \u001b[0;36mscale\u001b[1;34m(self, sx, sy)\u001b[0m\n\u001b[0;32m   1989\u001b[0m         scale_mtx = np.array(\n\u001b[0;32m   1990\u001b[0m             [[sx, 0.0, 0.0], [0.0, sy, 0.0], [0.0, 0.0, 1.0]], float)\n\u001b[1;32m-> 1991\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mtx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscale_mtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mtx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1992\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1993\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# In case of CartPole-v1, maximum length of episode is 500\n",
    "env = gym.make('CartPole-v1')\n",
    "# get size of state and action from environment\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n\n",
    "\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "\n",
    "scores, episodes = [], []\n",
    "\n",
    "for e in range(EPISODES):\n",
    "    done = False\n",
    "    score = 0\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1, state_size])\n",
    "\n",
    "    while not done:\n",
    "        if agent.render:\n",
    "            env.render()\n",
    "\n",
    "        # get action for the current state and go one step in environment\n",
    "        action = agent.get_action(state)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        next_state = np.reshape(next_state, [1, state_size])\n",
    "        # if an action make the episode end, then gives penalty of -100\n",
    "        reward = reward if not done or score == 499 else -100\n",
    "\n",
    "        # save the sample <s, a, r, s'> to the replay memory\n",
    "        agent.append_sample(state, action, reward, next_state, done)\n",
    "        # every time step do the training\n",
    "        agent.train_model()\n",
    "        score += reward\n",
    "        state = next_state\n",
    "\n",
    "        if done:\n",
    "            # every episode update the target model to be same with model\n",
    "            agent.update_target_model()\n",
    "\n",
    "            # every episode, plot the play time\n",
    "            score = score if score == 500 else score + 100\n",
    "            scores.append(score)\n",
    "            episodes.append(e)\n",
    "            pylab.plot(episodes, scores, 'b')\n",
    "            #pylab.savefig(\"./save_graph/cartpole_dqn.png\")\n",
    "            print(\"episode:\", e, \"  score:\", score, \"  memory length:\",\n",
    "                  len(agent.memory), \"  epsilon:\", agent.epsilon)\n",
    "\n",
    "            # if the mean of scores of last 10 episode is bigger than 490\n",
    "            # stop training\n",
    "            if np.mean(scores[-min(10, len(scores)):]) > 490:\n",
    "                sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the network\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(range(500)):\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1, state_size])\n",
    "    for j in range(1000):\n",
    "        env.render()\n",
    "        nn_out = agent.get_action(state)\n",
    "        print(nn_out)\n",
    "        state,reward,done,info = env.step(nn_out)\n",
    "        state = np.reshape(state, [1, state_size])\n",
    "        if done:\n",
    "            print(\"episode ended\")\n",
    "            break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SARSA (WITH NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pylab\n",
    "import random\n",
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "\n",
    "EPISODES = 1000\n",
    "\n",
    "\n",
    "# this is DeepSARSA Agent for the GridWorld\n",
    "# Utilize Neural Network as q function approximator\n",
    "class DeepSARSAgent:\n",
    "    def __init__(self):\n",
    "        self.load_model = False\n",
    "        # actions which agent can do\n",
    "        self.action_space = [0, 1]\n",
    "        # get size of state and action\n",
    "        self.action_size = len(self.action_space)\n",
    "        self.state_size = 4\n",
    "        self.discount_factor = 0.99\n",
    "        self.learning_rate = 0.001\n",
    "\n",
    "        self.epsilon = 1.  # exploration\n",
    "        self.epsilon_decay = .9999\n",
    "        self.epsilon_min = 0.01\n",
    "        self.model = self.build_model()\n",
    "\n",
    "        \n",
    "    # approximate Q function using Neural Network\n",
    "    # state is input and Q Value of each action is output of network\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(30, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dense(30, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.summary()\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    # get action from model using epsilon-greedy policy\n",
    "    def get_action(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            # The agent acts randomly\n",
    "            return random.randrange(self.action_size)\n",
    "        else:\n",
    "            # Predict the reward value based on the given state\n",
    "            state = np.float32(state)\n",
    "            q_values = self.model.predict(state)\n",
    "            return np.argmax(q_values[0])\n",
    "\n",
    "    def train_model(self, state, action, reward, next_state, next_action, done):\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "        state = np.float32(state)\n",
    "        next_state = np.float32(next_state)\n",
    "        target = self.model.predict(state)[0]\n",
    "\n",
    "        \n",
    "        # like Q Learning, get maximum Q value at s'\n",
    "        # But from target model\n",
    "        if done:\n",
    "            target[action] = reward\n",
    "        else:\n",
    "            target[action] = (reward + self.discount_factor *\n",
    "                              self.model.predict(next_state)[0][next_action])\n",
    "\n",
    "        target = np.reshape(target, [1, 2])\n",
    "\n",
    "        # make minibatch which includes target q value and predicted q value\n",
    "        # and do the model fit!\n",
    "        self.model.fit(state, target, epochs=1,verbose = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 30)                150       \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 2)                 62        \n",
      "=================================================================\n",
      "Total params: 1,142\n",
      "Trainable params: 1,142\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "episode: 0   score: 13.0 global_step 13   epsilon: 0.9987007797140718\n",
      "episode: 1   score: 22.0 global_step 35   epsilon: 0.9965059434602331\n",
      "episode: 2   score: 20.0 global_step 55   epsilon: 0.9945148237990713\n",
      "episode: 3   score: 14.0 global_step 69   epsilon: 0.9931234076923388\n",
      "episode: 4   score: 20.0 global_step 89   epsilon: 0.9911390466797494\n",
      "episode: 5   score: 14.0 global_step 103   epsilon: 0.9897523535902548\n",
      "episode: 6   score: 20.0 global_step 123   epsilon: 0.987774728284708\n",
      "episode: 7   score: 16.0 global_step 139   epsilon: 0.9861954734961524\n",
      "episode: 8   score: 14.0 global_step 153   epsilon: 0.9848156969122625\n",
      "episode: 9   score: 16.0 global_step 169   epsilon: 0.9832411730247218\n",
      "episode: 10   score: 15.0 global_step 184   epsilon: 0.981767343221176\n",
      "episode: 11   score: 26.0 global_step 210   epsilon: 0.9792179363215386\n",
      "episode: 12   score: 9.0 global_step 219   epsilon: 0.9783369926150645\n",
      "episode: 13   score: 43.0 global_step 262   epsilon: 0.974138965868271\n",
      "episode: 14   score: 37.0 global_step 299   epsilon: 0.9705411318974407\n",
      "episode: 15   score: 13.0 global_step 312   epsilon: 0.9692801851705518\n",
      "episode: 16   score: 26.0 global_step 338   epsilon: 0.9667632043310306\n",
      "episode: 17   score: 57.0 global_step 395   epsilon: 0.9612680553577415\n",
      "episode: 18   score: 32.0 global_step 427   epsilon: 0.9581967607057171\n",
      "episode: 19   score: 12.0 global_step 439   epsilon: 0.9570475567919766\n",
      "episode: 20   score: 14.0 global_step 453   epsilon: 0.9557085607774751\n",
      "episode: 21   score: 14.0 global_step 467   epsilon: 0.9543714381393948\n",
      "episode: 22   score: 12.0 global_step 479   epsilon: 0.9532268220888624\n",
      "episode: 23   score: 11.0 global_step 490   epsilon: 0.9521787967020661\n",
      "episode: 24   score: 34.0 global_step 524   epsilon: 0.948946724822904\n",
      "episode: 25   score: 20.0 global_step 544   epsilon: 0.9470506332906957\n",
      "episode: 26   score: 54.0 global_step 598   epsilon: 0.9419500887047652\n",
      "episode: 27   score: 16.0 global_step 614   epsilon: 0.9404440983756235\n",
      "episode: 28   score: 26.0 global_step 640   epsilon: 0.9380019977194178\n",
      "episode: 29   score: 21.0 global_step 661   epsilon: 0.9360341620814209\n",
      "episode: 30   score: 18.0 global_step 679   epsilon: 0.9343507319584249\n",
      "episode: 31   score: 22.0 global_step 701   epsilon: 0.9322973172600907\n",
      "episode: 32   score: 17.0 global_step 718   epsilon: 0.9307136791113598\n",
      "episode: 33   score: 11.0 global_step 729   epsilon: 0.9296904058033238\n",
      "episode: 34   score: 29.0 global_step 758   epsilon: 0.9269980747746605\n",
      "episode: 35   score: 13.0 global_step 771   epsilon: 0.9257937000708967\n",
      "episode: 36   score: 19.0 global_step 790   epsilon: 0.924036274251254\n",
      "episode: 37   score: 17.0 global_step 807   epsilon: 0.9224666686462353\n",
      "episode: 38   score: 13.0 global_step 820   epsilon: 0.9212681812372374\n",
      "episode: 39   score: 60.0 global_step 880   epsilon: 0.9157568471156993\n",
      "episode: 40   score: 12.0 global_step 892   epsilon: 0.9146585430972585\n",
      "episode: 41   score: 16.0 global_step 908   epsilon: 0.9131961865065122\n",
      "episode: 42   score: 16.0 global_step 924   epsilon: 0.9117361679323023\n",
      "episode: 43   score: 13.0 global_step 937   epsilon: 0.91055162180751\n",
      "episode: 44   score: 19.0 global_step 956   epsilon: 0.9088231298873775\n",
      "episode: 45   score: 44.0 global_step 1000   epsilon: 0.9048328935585562\n",
      "episode: 46   score: 15.0 global_step 1015   epsilon: 0.9034765938811813\n",
      "episode: 47   score: 11.0 global_step 1026   epsilon: 0.9024832663909947\n",
      "episode: 48   score: 16.0 global_step 1042   epsilon: 0.9010403756394627\n",
      "episode: 49   score: 22.0 global_step 1064   epsilon: 0.8990601668293806\n",
      "episode: 50   score: 15.0 global_step 1079   epsilon: 0.8977125201833623\n",
      "episode: 51   score: 41.0 global_step 1120   epsilon: 0.8940392505327455\n",
      "episode: 52   score: 12.0 global_step 1132   epsilon: 0.8929669933013674\n",
      "episode: 53   score: 27.0 global_step 1159   epsilon: 0.8905591141232382\n",
      "episode: 54   score: 15.0 global_step 1174   epsilon: 0.8892242101340405\n",
      "episode: 55   score: 16.0 global_step 1190   epsilon: 0.8878025179690746\n",
      "episode: 56   score: 12.0 global_step 1202   epsilon: 0.886737740701901\n",
      "episode: 57   score: 24.0 global_step 1226   epsilon: 0.8846120157265657\n",
      "episode: 58   score: 14.0 global_step 1240   epsilon: 0.8833743635795724\n",
      "episode: 59   score: 9.0 global_step 1249   epsilon: 0.8825796445929295\n",
      "episode: 60   score: 22.0 global_step 1271   epsilon: 0.880640006775277\n",
      "episode: 61   score: 17.0 global_step 1288   epsilon: 0.8791441158355427\n",
      "episode: 62   score: 21.0 global_step 1309   epsilon: 0.8772997582261961\n",
      "episode: 63   score: 17.0 global_step 1326   epsilon: 0.8758095411685276\n",
      "episode: 64   score: 18.0 global_step 1344   epsilon: 0.8742344232686299\n",
      "episode: 65   score: 39.0 global_step 1383   epsilon: 0.8708313791125161\n",
      "episode: 66   score: 17.0 global_step 1400   epsilon: 0.8693521495067424\n",
      "episode: 67   score: 27.0 global_step 1427   epsilon: 0.8670079475877893\n",
      "episode: 68   score: 24.0 global_step 1451   epsilon: 0.864929519701611\n",
      "episode: 69   score: 31.0 global_step 1482   epsilon: 0.8622522562276645\n",
      "episode: 70   score: 10.0 global_step 1492   epsilon: 0.8613903918815002\n",
      "episode: 71   score: 16.0 global_step 1508   epsilon: 0.8600132004407384\n",
      "episode: 72   score: 19.0 global_step 1527   epsilon: 0.8583806451494542\n",
      "episode: 73   score: 10.0 global_step 1537   epsilon: 0.8575226506726076\n",
      "episode: 74   score: 21.0 global_step 1558   epsilon: 0.8557236527637695\n",
      "episode: 75   score: 47.0 global_step 1605   epsilon: 0.8517109881081575\n",
      "episode: 76   score: 14.0 global_step 1619   epsilon: 0.850519367471868\n",
      "episode: 77   score: 19.0 global_step 1638   epsilon: 0.8489048342379664\n",
      "episode: 78   score: 30.0 global_step 1668   epsilon: 0.8463618090270535\n",
      "episode: 79   score: 24.0 global_step 1692   epsilon: 0.8443328749318442\n",
      "episode: 80   score: 9.0 global_step 1701   epsilon: 0.8435732792333273\n",
      "episode: 81   score: 33.0 global_step 1734   epsilon: 0.8407939368796862\n",
      "episode: 82   score: 16.0 global_step 1750   epsilon: 0.8394496750627115\n",
      "episode: 83   score: 19.0 global_step 1769   epsilon: 0.8378561553259353\n",
      "episode: 84   score: 16.0 global_step 1785   epsilon: 0.8365165904357533\n",
      "episode: 85   score: 16.0 global_step 1801   epsilon: 0.8351791672426676\n",
      "episode: 86   score: 18.0 global_step 1819   epsilon: 0.8336771218845062\n",
      "episode: 87   score: 17.0 global_step 1836   epsilon: 0.8322610040114864\n",
      "episode: 88   score: 23.0 global_step 1859   epsilon: 0.8303489078494027\n",
      "episode: 89   score: 9.0 global_step 1868   epsilon: 0.8296018926882063\n",
      "episode: 90   score: 16.0 global_step 1884   epsilon: 0.8282755247177503\n",
      "episode: 91   score: 9.0 global_step 1893   epsilon: 0.8275303748551286\n",
      "episode: 92   score: 33.0 global_step 1926   epsilon: 0.8248038894668648\n",
      "episode: 93   score: 44.0 global_step 1970   epsilon: 0.8211825440854905\n",
      "episode: 94   score: 26.0 global_step 1996   epsilon: 0.8190501361802892\n",
      "episode: 95   score: 14.0 global_step 2010   epsilon: 0.8179042110272086\n",
      "episode: 96   score: 25.0 global_step 2035   epsilon: 0.8158619023321285\n",
      "episode: 97   score: 19.0 global_step 2054   epsilon: 0.8143131590512966\n",
      "episode: 98   score: 12.0 global_step 2066   epsilon: 0.8133365205280116\n",
      "episode: 99   score: 25.0 global_step 2091   epsilon: 0.8113056173666077\n",
      "episode: 100   score: 12.0 global_step 2103   epsilon: 0.8103325859090281\n",
      "episode: 101   score: 16.0 global_step 2119   epsilon: 0.8090370257170382\n",
      "episode: 102   score: 15.0 global_step 2134   epsilon: 0.8078243192993382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 103   score: 35.0 global_step 2169   epsilon: 0.8050017354535077\n",
      "episode: 104   score: 19.0 global_step 2188   epsilon: 0.803473607929379\n",
      "episode: 105   score: 13.0 global_step 2201   epsilon: 0.802429718718749\n",
      "episode: 106   score: 20.0 global_step 2221   epsilon: 0.800826382983396\n",
      "episode: 107   score: 22.0 global_step 2243   epsilon: 0.7990664136170905\n",
      "episode: 108   score: 18.0 global_step 2261   epsilon: 0.797629315992399\n",
      "episode: 109   score: 10.0 global_step 2271   epsilon: 0.7968320455139001\n",
      "episode: 110   score: 12.0 global_step 2283   epsilon: 0.7958763727931698\n",
      "episode: 111   score: 15.0 global_step 2298   epsilon: 0.7946833935421564\n",
      "episode: 112   score: 21.0 global_step 2319   epsilon: 0.793016226194391\n",
      "episode: 113   score: 30.0 global_step 2349   epsilon: 0.7906406239189183\n",
      "episode: 114   score: 15.0 global_step 2364   epsilon: 0.7894554927960618\n",
      "episode: 115   score: 31.0 global_step 2395   epsilon: 0.787011848190316\n",
      "episode: 116   score: 63.0 global_step 2458   epsilon: 0.7820690126819095\n",
      "episode: 117   score: 23.0 global_step 2481   epsilon: 0.7802722312029914\n",
      "episode: 118   score: 30.0 global_step 2511   epsilon: 0.7779348055278205\n",
      "episode: 119   score: 15.0 global_step 2526   epsilon: 0.7767687197972204\n",
      "episode: 120   score: 69.0 global_step 2595   epsilon: 0.7714271979938307\n",
      "episode: 121   score: 52.0 global_step 2647   epsilon: 0.7674259886612321\n",
      "episode: 122   score: 15.0 global_step 2662   epsilon: 0.7662756551264543\n",
      "episode: 123   score: 16.0 global_step 2678   epsilon: 0.7650505331800633\n",
      "episode: 124   score: 16.0 global_step 2694   epsilon: 0.763827369959326\n",
      "episode: 125   score: 16.0 global_step 2710   epsilon: 0.762606162332631\n",
      "episode: 126   score: 10.0 global_step 2720   epsilon: 0.7618438992515748\n",
      "episode: 127   score: 21.0 global_step 2741   epsilon: 0.7602456259225383\n",
      "episode: 128   score: 24.0 global_step 2765   epsilon: 0.7584231331603222\n",
      "episode: 129   score: 39.0 global_step 2804   epsilon: 0.7554708959314187\n",
      "episode: 130   score: 31.0 global_step 2835   epsilon: 0.7531324457002317\n",
      "episode: 131   score: 32.0 global_step 2867   epsilon: 0.7507261536780917\n",
      "episode: 132   score: 13.0 global_step 2880   epsilon: 0.7497507950300561\n",
      "episode: 133   score: 14.0 global_step 2894   epsilon: 0.7487018259174034\n",
      "episode: 134   score: 12.0 global_step 2906   epsilon: 0.7478038777048304\n",
      "episode: 135   score: 15.0 global_step 2921   epsilon: 0.7466829567421964\n",
      "episode: 136   score: 17.0 global_step 2938   epsilon: 0.7454146106969893\n",
      "episode: 137   score: 43.0 global_step 2981   epsilon: 0.7422160497749571\n",
      "episode: 138   score: 17.0 global_step 2998   epsilon: 0.740955291399637\n",
      "episode: 139   score: 31.0 global_step 3029   epsilon: 0.7386617721101394\n",
      "episode: 140   score: 15.0 global_step 3044   epsilon: 0.7375545547108445\n",
      "episode: 141   score: 19.0 global_step 3063   epsilon: 0.736154461560778\n",
      "episode: 142   score: 12.0 global_step 3075   epsilon: 0.7352715619069324\n",
      "episode: 143   score: 11.0 global_step 3086   epsilon: 0.7344631674668985\n",
      "episode: 144   score: 22.0 global_step 3108   epsilon: 0.7328490439778524\n",
      "episode: 145   score: 17.0 global_step 3125   epsilon: 0.7316041967796272\n",
      "episode: 146   score: 26.0 global_step 3151   epsilon: 0.7297044016805622\n",
      "episode: 147   score: 18.0 global_step 3169   epsilon: 0.7283920496100564\n",
      "episode: 148   score: 25.0 global_step 3194   epsilon: 0.7265732529877998\n",
      "episode: 149   score: 20.0 global_step 3214   epsilon: 0.7251214861430635\n",
      "episode: 150   score: 16.0 global_step 3230   epsilon: 0.7239621615050822\n",
      "episode: 151   score: 12.0 global_step 3242   epsilon: 0.7230938845670669\n",
      "episode: 152   score: 17.0 global_step 3259   epsilon: 0.7218656078794543\n",
      "episode: 153   score: 52.0 global_step 3311   epsilon: 0.7181214627227361\n",
      "episode: 154   score: 12.0 global_step 3323   epsilon: 0.717260190769683\n",
      "episode: 155   score: 16.0 global_step 3339   epsilon: 0.7161134347751452\n",
      "episode: 156   score: 34.0 global_step 3373   epsilon: 0.7136826622113753\n",
      "episode: 157   score: 17.0 global_step 3390   epsilon: 0.7124703718089022\n",
      "episode: 158   score: 21.0 global_step 3411   epsilon: 0.7109756792687252\n",
      "episode: 159   score: 11.0 global_step 3422   epsilon: 0.7101939969408656\n",
      "episode: 160   score: 12.0 global_step 3434   epsilon: 0.709342232716367\n",
      "episode: 161   score: 11.0 global_step 3445   epsilon: 0.708562346281589\n",
      "episode: 162   score: 13.0 global_step 3458   epsilon: 0.7076417677074551\n",
      "episode: 163   score: 15.0 global_step 3473   epsilon: 0.7065810477578696\n",
      "episode: 164   score: 13.0 global_step 3486   epsilon: 0.7056630433269699\n",
      "episode: 165   score: 25.0 global_step 3511   epsilon: 0.7039010010856502\n",
      "episode: 166   score: 17.0 global_step 3528   epsilon: 0.7027053262106808\n",
      "episode: 167   score: 25.0 global_step 3553   epsilon: 0.7009506693957991\n",
      "episode: 168   score: 11.0 global_step 3564   epsilon: 0.7001800090666982\n",
      "episode: 169   score: 11.0 global_step 3575   epsilon: 0.6994101960402234\n",
      "episode: 170   score: 16.0 global_step 3591   epsilon: 0.6982919786272518\n",
      "episode: 171   score: 73.0 global_step 3664   epsilon: 0.6932127549414036\n",
      "episode: 172   score: 24.0 global_step 3688   epsilon: 0.691550956194422\n",
      "episode: 173   score: 12.0 global_step 3700   epsilon: 0.6907215513185129\n",
      "episode: 174   score: 16.0 global_step 3716   epsilon: 0.6896172253155864\n",
      "episode: 175   score: 23.0 global_step 3739   epsilon: 0.6880328492082393\n",
      "episode: 176   score: 14.0 global_step 3753   epsilon: 0.6870702290788655\n",
      "episode: 177   score: 56.0 global_step 3809   epsilon: 0.6832331976571747\n",
      "episode: 178   score: 27.0 global_step 3836   epsilon: 0.6813908641747658\n",
      "episode: 179   score: 35.0 global_step 3871   epsilon: 0.6790100459696586\n",
      "episode: 180   score: 50.0 global_step 3921   epsilon: 0.6756233003198998\n",
      "episode: 181   score: 15.0 global_step 3936   epsilon: 0.6746105744665689\n",
      "episode: 182   score: 21.0 global_step 3957   epsilon: 0.6731953080455672\n",
      "episode: 183   score: 14.0 global_step 3971   epsilon: 0.6722534469770582\n",
      "episode: 184   score: 19.0 global_step 3990   epsilon: 0.6709773143300432\n",
      "episode: 185   score: 44.0 global_step 4034   epsilon: 0.6680313527150629\n",
      "episode: 186   score: 23.0 global_step 4057   epsilon: 0.6664965695406484\n",
      "episode: 187   score: 12.0 global_step 4069   epsilon: 0.6656972133983393\n",
      "episode: 188   score: 13.0 global_step 4082   epsilon: 0.6648323260744061\n",
      "episode: 189   score: 12.0 global_step 4094   epsilon: 0.664034965926222\n",
      "episode: 190   score: 13.0 global_step 4107   epsilon: 0.6631722382279249\n",
      "episode: 191   score: 13.0 global_step 4120   epsilon: 0.6623106314029545\n",
      "episode: 192   score: 20.0 global_step 4140   epsilon: 0.6609872677756349\n",
      "episode: 193   score: 26.0 global_step 4166   epsilon: 0.6592708473704595\n",
      "episode: 194   score: 13.0 global_step 4179   epsilon: 0.6584143093116347\n",
      "episode: 195   score: 17.0 global_step 4196   epsilon: 0.6572958999817007\n",
      "episode: 196   score: 11.0 global_step 4207   epsilon: 0.6565732358960337\n",
      "episode: 197   score: 67.0 global_step 4274   epsilon: 0.6521886806468971\n",
      "episode: 198   score: 22.0 global_step 4296   epsilon: 0.6507553711014326\n",
      "episode: 199   score: 14.0 global_step 4310   epsilon: 0.6498449055324687\n",
      "episode: 200   score: 20.0 global_step 4330   epsilon: 0.6485464496862162\n",
      "episode: 201   score: 44.0 global_step 4374   epsilon: 0.6456989719764586\n",
      "episode: 202   score: 21.0 global_step 4395   epsilon: 0.6443443592447561\n",
      "episode: 203   score: 17.0 global_step 4412   epsilon: 0.6432498497043679\n",
      "episode: 204   score: 18.0 global_step 4430   epsilon: 0.6420929836224754\n",
      "episode: 205   score: 20.0 global_step 4450   epsilon: 0.6408100169002243\n",
      "episode: 206   score: 66.0 global_step 4516   epsilon: 0.6365943868862066\n",
      "episode: 207   score: 14.0 global_step 4530   epsilon: 0.6357037338138014\n",
      "episode: 208   score: 27.0 global_step 4557   epsilon: 0.6339895631942916\n",
      "episode: 209   score: 14.0 global_step 4571   epsilon: 0.6331025545056134\n",
      "episode: 210   score: 74.0 global_step 4645   epsilon: 0.6284346547347734\n",
      "episode: 211   score: 30.0 global_step 4675   epsilon: 0.6265520819115943\n",
      "episode: 212   score: 32.0 global_step 4707   epsilon: 0.624550219842357\n",
      "episode: 213   score: 31.0 global_step 4738   epsilon: 0.6226170155139792\n",
      "episode: 214   score: 12.0 global_step 4750   epsilon: 0.6218702858856479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 215   score: 14.0 global_step 4764   epsilon: 0.6210002331610694\n",
      "episode: 216   score: 28.0 global_step 4792   epsilon: 0.6192637778559741\n",
      "episode: 217   score: 43.0 global_step 4835   epsilon: 0.6166065279284098\n",
      "episode: 218   score: 31.0 global_step 4866   epsilon: 0.6146979121424796\n",
      "episode: 219   score: 15.0 global_step 4881   epsilon: 0.6137765104274701\n",
      "episode: 220   score: 24.0 global_step 4905   epsilon: 0.6123051395839814\n",
      "episode: 221   score: 17.0 global_step 4922   epsilon: 0.6112650531654568\n",
      "episode: 222   score: 13.0 global_step 4935   epsilon: 0.6104708852083052\n",
      "episode: 223   score: 65.0 global_step 5000   epsilon: 0.6065154956247766\n",
      "episode: 224   score: 30.0 global_step 5030   epsilon: 0.6046985850195162\n",
      "episode: 225   score: 56.0 global_step 5086   epsilon: 0.6013215685615586\n",
      "episode: 226   score: 16.0 global_step 5102   epsilon: 0.600360175301112\n",
      "episode: 227   score: 21.0 global_step 5123   epsilon: 0.599100678891228\n",
      "episode: 228   score: 24.0 global_step 5147   epsilon: 0.5976644895678195\n",
      "episode: 229   score: 14.0 global_step 5161   epsilon: 0.59682830293962\n",
      "episode: 230   score: 13.0 global_step 5174   epsilon: 0.5960528915012249\n",
      "episode: 231   score: 27.0 global_step 5201   epsilon: 0.5944456390974114\n",
      "episode: 232   score: 14.0 global_step 5215   epsilon: 0.5936139559318881\n",
      "episode: 233   score: 28.0 global_step 5243   epsilon: 0.5919540787725678\n",
      "episode: 234   score: 18.0 global_step 5261   epsilon: 0.5908894666376643\n",
      "episode: 235   score: 18.0 global_step 5279   epsilon: 0.5898267691766154\n",
      "episode: 236   score: 32.0 global_step 5311   epsilon: 0.5879422461326045\n",
      "episode: 237   score: 73.0 global_step 5384   epsilon: 0.583665682354315\n",
      "episode: 238   score: 55.0 global_step 5439   epsilon: 0.5804641732441663\n",
      "episode: 239   score: 25.0 global_step 5464   epsilon: 0.5790147528692422\n",
      "episode: 240   score: 30.0 global_step 5494   epsilon: 0.5772802249755956\n",
      "episode: 241   score: 27.0 global_step 5521   epsilon: 0.575723592934219\n",
      "episode: 242   score: 21.0 global_step 5542   epsilon: 0.5745157816432345\n",
      "episode: 243   score: 17.0 global_step 5559   epsilon: 0.5735398857653701\n",
      "episode: 244   score: 14.0 global_step 5573   epsilon: 0.5727374516378836\n",
      "episode: 245   score: 24.0 global_step 5597   epsilon: 0.5713644613507072\n",
      "episode: 246   score: 61.0 global_step 5658   epsilon: 0.5678895735724869\n",
      "episode: 247   score: 39.0 global_step 5697   epsilon: 0.5656790071120201\n",
      "episode: 248   score: 20.0 global_step 5717   epsilon: 0.5645487232433097\n",
      "episode: 249   score: 29.0 global_step 5746   epsilon: 0.5629138219521997\n",
      "episode: 250   score: 25.0 global_step 5771   epsilon: 0.5615082248447955\n",
      "episode: 251   score: 41.0 global_step 5812   epsilon: 0.5592106395103803\n",
      "episode: 252   score: 26.0 global_step 5838   epsilon: 0.55775850782912\n",
      "episode: 253   score: 38.0 global_step 5876   epsilon: 0.5556429418405433\n",
      "episode: 254   score: 29.0 global_step 5905   epsilon: 0.5540338311905497\n",
      "episode: 255   score: 41.0 global_step 5946   epsilon: 0.5517668296596904\n",
      "episode: 256   score: 147.0 global_step 6093   epsilon: 0.5437147822073575\n",
      "episode: 257   score: 35.0 global_step 6128   epsilon: 0.5418150120168181\n",
      "episode: 258   score: 24.0 global_step 6152   epsilon: 0.5405161503013532\n",
      "episode: 259   score: 22.0 global_step 6174   epsilon: 0.539328262530998\n",
      "episode: 260   score: 53.0 global_step 6227   epsilon: 0.5364772420645153\n",
      "episode: 261   score: 23.0 global_step 6250   epsilon: 0.5352447007455633\n",
      "episode: 262   score: 39.0 global_step 6289   epsilon: 0.5331612076886864\n",
      "episode: 263   score: 29.0 global_step 6318   epsilon: 0.5316172028739871\n",
      "episode: 264   score: 27.0 global_step 6345   epsilon: 0.5301837008485618\n",
      "episode: 265   score: 93.0 global_step 6438   epsilon: 0.5252756050440994\n",
      "episode: 266   score: 19.0 global_step 6457   epsilon: 0.5242784791070118\n",
      "episode: 267   score: 22.0 global_step 6479   epsilon: 0.5231262767292576\n",
      "episode: 268   score: 29.0 global_step 6508   epsilon: 0.5216113325091649\n",
      "episode: 269   score: 44.0 global_step 6552   epsilon: 0.5193211701881851\n",
      "episode: 270   score: 32.0 global_step 6584   epsilon: 0.5176619157026207\n",
      "episode: 271   score: 25.0 global_step 6609   epsilon: 0.5163693127091433\n",
      "episode: 272   score: 12.0 global_step 6621   epsilon: 0.5157500102240632\n",
      "episode: 273   score: 27.0 global_step 6648   epsilon: 0.5143592939713303\n",
      "episode: 274   score: 27.0 global_step 6675   epsilon: 0.512972327775131\n",
      "episode: 275   score: 76.0 global_step 6751   epsilon: 0.5090883217991456\n",
      "episode: 276   score: 20.0 global_step 6771   epsilon: 0.5080711118432447\n",
      "episode: 277   score: 34.0 global_step 6805   epsilon: 0.5063465173039727\n",
      "episode: 278   score: 37.0 global_step 6842   epsilon: 0.504476403526783\n",
      "episode: 279   score: 20.0 global_step 6862   epsilon: 0.5034684086500377\n",
      "episode: 280   score: 62.0 global_step 6924   epsilon: 0.500356406090893\n",
      "episode: 281   score: 23.0 global_step 6947   epsilon: 0.49920685137290327\n",
      "episode: 282   score: 24.0 global_step 6971   epsilon: 0.49801013173065367\n",
      "episode: 283   score: 14.0 global_step 6985   epsilon: 0.497313370554225\n",
      "episode: 284   score: 18.0 global_step 7003   epsilon: 0.4964189669710287\n",
      "episode: 285   score: 12.0 global_step 7015   epsilon: 0.4958235917379941\n",
      "episode: 286   score: 37.0 global_step 7052   epsilon: 0.49399234278440785\n",
      "episode: 287   score: 20.0 global_step 7072   epsilon: 0.49300529612137833\n",
      "episode: 288   score: 15.0 global_step 7087   epsilon: 0.4922663056085073\n",
      "episode: 289   score: 10.0 global_step 7097   epsilon: 0.4917742607636748\n",
      "episode: 290   score: 20.0 global_step 7117   epsilon: 0.4907916460528586\n",
      "episode: 291   score: 13.0 global_step 7130   epsilon: 0.4901539995901426\n",
      "episode: 292   score: 12.0 global_step 7142   epsilon: 0.4895661381844647\n",
      "episode: 293   score: 23.0 global_step 7165   epsilon: 0.48844137380238173\n",
      "episode: 294   score: 52.0 global_step 7217   epsilon: 0.48590794460988257\n",
      "episode: 295   score: 67.0 global_step 7284   epsilon: 0.4826630815654291\n",
      "episode: 296   score: 30.0 global_step 7314   epsilon: 0.48121718994684787\n",
      "episode: 297   score: 30.0 global_step 7344   epsilon: 0.47977562971936005\n",
      "episode: 298   score: 38.0 global_step 7382   epsilon: 0.4779558511052554\n",
      "episode: 299   score: 58.0 global_step 7440   epsilon: 0.47519159305151454\n",
      "episode: 300   score: 84.0 global_step 7524   epsilon: 0.4712165036622021\n",
      "episode: 301   score: 33.0 global_step 7557   epsilon: 0.4696639746542264\n",
      "episode: 302   score: 34.0 global_step 7591   epsilon: 0.4680697491470076\n",
      "episode: 303   score: 34.0 global_step 7625   epsilon: 0.46648093507244065\n",
      "episode: 304   score: 21.0 global_step 7646   epsilon: 0.4655023040986118\n",
      "episode: 305   score: 19.0 global_step 7665   epsilon: 0.46461864527887325\n",
      "episode: 306   score: 32.0 global_step 7697   epsilon: 0.4631341678196229\n",
      "episode: 307   score: 49.0 global_step 7746   epsilon: 0.4608702483321406\n",
      "episode: 308   score: 22.0 global_step 7768   epsilon: 0.4598573976866803\n",
      "episode: 309   score: 15.0 global_step 7783   epsilon: 0.45916809423124555\n",
      "episode: 310   score: 15.0 global_step 7798   epsilon: 0.45847982400753895\n",
      "episode: 311   score: 14.0 global_step 7812   epsilon: 0.45783836930372745\n",
      "episode: 312   score: 21.0 global_step 7833   epsilon: 0.45687786958011406\n",
      "episode: 313   score: 17.0 global_step 7850   epsilon: 0.4561017982451624\n",
      "episode: 314   score: 52.0 global_step 7902   epsilon: 0.4537361067366188\n",
      "episode: 315   score: 60.0 global_step 7962   epsilon: 0.45102170572054007\n",
      "episode: 316   score: 65.0 global_step 8027   epsilon: 0.44809942621470633\n",
      "episode: 317   score: 23.0 global_step 8050   epsilon: 0.4470699304327735\n",
      "episode: 318   score: 23.0 global_step 8073   epsilon: 0.44604279988833706\n",
      "episode: 319   score: 68.0 global_step 8141   epsilon: 0.4430198473864759\n",
      "episode: 320   score: 27.0 global_step 8168   epsilon: 0.441825247503141\n",
      "episode: 321   score: 32.0 global_step 8200   epsilon: 0.4404135959744933\n",
      "episode: 322   score: 93.0 global_step 8293   epsilon: 0.43633653340321665\n",
      "episode: 323   score: 17.0 global_step 8310   epsilon: 0.43559535441751174\n",
      "episode: 324   score: 33.0 global_step 8343   epsilon: 0.4341601873165787\n",
      "episode: 325   score: 23.0 global_step 8366   epsilon: 0.43316271654251126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 326   score: 63.0 global_step 8429   epsilon: 0.4304422339205948\n",
      "episode: 327   score: 73.0 global_step 8502   epsilon: 0.42731129090988323\n",
      "episode: 328   score: 30.0 global_step 8532   epsilon: 0.4260312141075558\n",
      "episode: 329   score: 31.0 global_step 8563   epsilon: 0.4247124964752977\n",
      "episode: 330   score: 70.0 global_step 8633   epsilon: 0.42174974259688924\n",
      "episode: 331   score: 44.0 global_step 8677   epsilon: 0.4198980279020955\n",
      "episode: 332   score: 38.0 global_step 8715   epsilon: 0.41830536374004157\n",
      "episode: 333   score: 43.0 global_step 8758   epsilon: 0.41651042281624584\n",
      "episode: 334   score: 21.0 global_step 8779   epsilon: 0.4156366250465101\n",
      "episode: 335   score: 20.0 global_step 8799   epsilon: 0.4148061410323803\n",
      "episode: 336   score: 17.0 global_step 8816   epsilon: 0.41410153444700754\n",
      "episode: 337   score: 22.0 global_step 8838   epsilon: 0.4131914670083552\n",
      "episode: 338   score: 11.0 global_step 8849   epsilon: 0.4127371835817899\n",
      "episode: 339   score: 18.0 global_step 8867   epsilon: 0.41199488780256643\n",
      "episode: 340   score: 17.0 global_step 8884   epsilon: 0.41129505652629106\n",
      "episode: 341   score: 102.0 global_step 8986   epsilon: 0.4071209623131647\n",
      "episode: 342   score: 28.0 global_step 9014   epsilon: 0.4059825612030304\n",
      "episode: 343   score: 22.0 global_step 9036   epsilon: 0.40509033676318373\n",
      "episode: 344   score: 26.0 global_step 9062   epsilon: 0.4040384173785645\n",
      "episode: 345   score: 24.0 global_step 9086   epsilon: 0.4030698395055434\n",
      "episode: 346   score: 39.0 global_step 9125   epsilon: 0.4015008501986404\n",
      "episode: 347   score: 37.0 global_step 9162   epsilon: 0.4000179679315563\n",
      "episode: 348   score: 62.0 global_step 9224   epsilon: 0.397545405763764\n",
      "episode: 349   score: 41.0 global_step 9265   epsilon: 0.39591872523864896\n",
      "episode: 350   score: 45.0 global_step 9310   epsilon: 0.3941410049582625\n",
      "episode: 351   score: 32.0 global_step 9342   epsilon: 0.39288170672825795\n",
      "episode: 352   score: 54.0 global_step 9396   epsilon: 0.3907657579165237\n",
      "episode: 353   score: 41.0 global_step 9437   epsilon: 0.3891668184266723\n",
      "episode: 354   score: 18.0 global_step 9455   epsilon: 0.3884669132612955\n",
      "episode: 355   score: 19.0 global_step 9474   epsilon: 0.3877294900282468\n",
      "episode: 356   score: 73.0 global_step 9547   epsilon: 0.38490923020895895\n",
      "episode: 357   score: 13.0 global_step 9560   epsilon: 0.38440914832883033\n",
      "episode: 358   score: 12.0 global_step 9572   epsilon: 0.3839481109763226\n",
      "episode: 359   score: 13.0 global_step 9585   epsilon: 0.3834492778017982\n",
      "episode: 360   score: 26.0 global_step 9611   epsilon: 0.3824535548932714\n",
      "episode: 361   score: 14.0 global_step 9625   epsilon: 0.38191846780998107\n",
      "episode: 362   score: 79.0 global_step 9704   epsilon: 0.37891304867784265\n",
      "episode: 363   score: 14.0 global_step 9718   epsilon: 0.37838291508268157\n",
      "episode: 364   score: 11.0 global_step 9729   epsilon: 0.37796690192427324\n",
      "episode: 365   score: 14.0 global_step 9743   epsilon: 0.3774380920739178\n",
      "episode: 366   score: 12.0 global_step 9755   epsilon: 0.3769854153895522\n",
      "episode: 367   score: 15.0 global_step 9770   epsilon: 0.3764203329296772\n",
      "episode: 368   score: 11.0 global_step 9781   epsilon: 0.37600647753254074\n",
      "episode: 369   score: 38.0 global_step 9819   epsilon: 0.3745802930742372\n",
      "episode: 370   score: 63.0 global_step 9882   epsilon: 0.37222773792832137\n",
      "episode: 371   score: 64.0 global_step 9946   epsilon: 0.3698529690319025\n",
      "episode: 372   score: 64.0 global_step 10010   epsilon: 0.36749335087987156\n",
      "episode: 373   score: 31.0 global_step 10041   epsilon: 0.36635582868549893\n",
      "episode: 374   score: 134.0 global_step 10175   epsilon: 0.3614791633759571\n",
      "episode: 375   score: 19.0 global_step 10194   epsilon: 0.36079297074477895\n",
      "episode: 376   score: 123.0 global_step 10317   epsilon: 0.35638217864445665\n",
      "episode: 377   score: 65.0 global_step 10382   epsilon: 0.35407309168990936\n",
      "episode: 378   score: 37.0 global_step 10419   epsilon: 0.3527653766286364\n",
      "episode: 379   score: 142.0 global_step 10561   epsilon: 0.34779125938855593\n",
      "episode: 380   score: 19.0 global_step 10580   epsilon: 0.34713105038189646\n",
      "episode: 381   score: 22.0 global_step 10602   epsilon: 0.34636816340945475\n",
      "episode: 382   score: 26.0 global_step 10628   epsilon: 0.3454687309810816\n",
      "episode: 383   score: 85.0 global_step 10713   epsilon: 0.34254454594932904\n",
      "episode: 384   score: 23.0 global_step 10736   epsilon: 0.3417575595250037\n",
      "episode: 385   score: 19.0 global_step 10755   epsilon: 0.34110880423630247\n",
      "episode: 386   score: 16.0 global_step 10771   epsilon: 0.34056343928913074\n",
      "episode: 387   score: 33.0 global_step 10804   epsilon: 0.3394413762577149\n",
      "episode: 388   score: 17.0 global_step 10821   epsilon: 0.3388647873276093\n",
      "episode: 389   score: 32.0 global_step 10853   epsilon: 0.33778209909795465\n",
      "episode: 390   score: 135.0 global_step 10988   epsilon: 0.3332524581478762\n",
      "episode: 391   score: 25.0 global_step 11013   epsilon: 0.3324203259938218\n",
      "episode: 392   score: 17.0 global_step 11030   epsilon: 0.3318556633053091\n",
      "episode: 393   score: 47.0 global_step 11077   epsilon: 0.3302995236723691\n",
      "episode: 394   score: 120.0 global_step 11197   epsilon: 0.32635942028367165\n",
      "episode: 395   score: 26.0 global_step 11223   epsilon: 0.32551194561100333\n",
      "episode: 396   score: 58.0 global_step 11281   epsilon: 0.32362934700871976\n",
      "episode: 397   score: 107.0 global_step 11388   epsilon: 0.32018480194709353\n",
      "episode: 398   score: 167.0 global_step 11555   epsilon: 0.3148818534730243\n",
      "episode: 399   score: 121.0 global_step 11676   epsilon: 0.31109455305576716\n",
      "episode: 400   score: 42.0 global_step 11718   epsilon: 0.3097906308891489\n",
      "episode: 401   score: 170.0 global_step 11888   epsilon: 0.3045684434171844\n",
      "episode: 402   score: 16.0 global_step 11904   epsilon: 0.3040814992193462\n",
      "episode: 403   score: 17.0 global_step 11921   epsilon: 0.3035649740148093\n",
      "episode: 404   score: 42.0 global_step 11963   epsilon: 0.30229261133684293\n",
      "episode: 405   score: 16.0 global_step 11979   epsilon: 0.3018093057406087\n",
      "episode: 406   score: 20.0 global_step 11999   epsilon: 0.30120626022289204\n",
      "episode: 407   score: 70.0 global_step 12069   epsilon: 0.2991050740720667\n",
      "episode: 408   score: 27.0 global_step 12096   epsilon: 0.2982985393565247\n",
      "episode: 409   score: 88.0 global_step 12184   epsilon: 0.2956848984136287\n",
      "episode: 410   score: 86.0 global_step 12270   epsilon: 0.29315278537260375\n",
      "episode: 411   score: 65.0 global_step 12335   epsilon: 0.29125337706052756\n",
      "episode: 412   score: 34.0 global_step 12369   epsilon: 0.2902647477684568\n",
      "episode: 413   score: 65.0 global_step 12434   epsilon: 0.28838405175557963\n",
      "episode: 414   score: 73.0 global_step 12507   epsilon: 0.2862864090056551\n",
      "episode: 415   score: 72.0 global_step 12579   epsilon: 0.28423244729672004\n",
      "episode: 416   score: 69.0 global_step 12648   epsilon: 0.2822778966360516\n",
      "episode: 417   score: 27.0 global_step 12675   epsilon: 0.28151673628538365\n",
      "episode: 418   score: 35.0 global_step 12710   epsilon: 0.2805331008919119\n",
      "episode: 419   score: 43.0 global_step 12753   epsilon: 0.2793293383133781\n",
      "episode: 420   score: 32.0 global_step 12785   epsilon: 0.27843686851982374\n",
      "episode: 421   score: 119.0 global_step 12904   epsilon: 0.2751429428162639\n",
      "episode: 422   score: 86.0 global_step 12990   epsilon: 0.2727867418828081\n",
      "episode: 423   score: 27.0 global_step 13017   epsilon: 0.272051174363766\n",
      "episode: 424   score: 48.0 global_step 13065   epsilon: 0.2707483927639587\n",
      "episode: 425   score: 145.0 global_step 13210   epsilon: 0.26685067294282017\n",
      "episode: 426   score: 96.0 global_step 13306   epsilon: 0.2643010368341152\n",
      "episode: 427   score: 59.0 global_step 13365   epsilon: 0.26274617432738784\n",
      "episode: 428   score: 43.0 global_step 13408   epsilon: 0.26161873513642386\n",
      "episode: 429   score: 268.0 global_step 13676   epsilon: 0.25470013051795637\n",
      "episode: 430   score: 29.0 global_step 13705   epsilon: 0.2539625332919146\n",
      "episode: 431   score: 37.0 global_step 13742   epsilon: 0.2530245613375936\n",
      "episode: 432   score: 29.0 global_step 13771   epsilon: 0.2522918164654825\n",
      "episode: 433   score: 54.0 global_step 13825   epsilon: 0.25093304470258726\n",
      "episode: 434   score: 54.0 global_step 13879   epsilon: 0.24958159089684762\n",
      "episode: 435   score: 114.0 global_step 13993   epsilon: 0.24675237646168277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 436   score: 59.0 global_step 14052   epsilon: 0.24530075136326532\n",
      "episode: 437   score: 223.0 global_step 14275   epsilon: 0.23989081905345078\n",
      "episode: 438   score: 30.0 global_step 14305   epsilon: 0.23917218914805372\n",
      "episode: 439   score: 60.0 global_step 14365   epsilon: 0.23774138118809096\n",
      "episode: 440   score: 145.0 global_step 14510   epsilon: 0.2343188334702565\n",
      "episode: 441   score: 328.0 global_step 14838   epsilon: 0.22675748174890267\n",
      "episode: 442   score: 34.0 global_step 14872   epsilon: 0.22598777706456336\n",
      "episode: 443   score: 18.0 global_step 14890   epsilon: 0.22558134464280916\n",
      "episode: 444   score: 28.0 global_step 14918   epsilon: 0.2249505688367493\n",
      "episode: 445   score: 136.0 global_step 15054   epsilon: 0.22191179962994384\n",
      "episode: 446   score: 223.0 global_step 15277   epsilon: 0.2170176938920887\n",
      "episode: 447   score: 32.0 global_step 15309   epsilon: 0.21632431260376803\n",
      "episode: 448   score: 129.0 global_step 15438   epsilon: 0.21355151333778116\n",
      "episode: 449   score: 108.0 global_step 15546   epsilon: 0.21125745251655806\n",
      "episode: 450   score: 210.0 global_step 15756   epsilon: 0.20686708668580925\n",
      "episode: 451   score: 18.0 global_step 15774   epsilon: 0.2064950422676772\n",
      "episode: 452   score: 22.0 global_step 15796   epsilon: 0.20604122986038467\n",
      "episode: 453   score: 49.0 global_step 15845   epsilon: 0.20503404708718997\n",
      "episode: 454   score: 48.0 global_step 15893   epsilon: 0.20405219290293988\n",
      "episode: 455   score: 37.0 global_step 15930   epsilon: 0.2032985571926651\n",
      "episode: 456   score: 38.0 global_step 15968   epsilon: 0.20252745015066306\n",
      "episode: 457   score: 27.0 global_step 15995   epsilon: 0.20198133631456877\n",
      "episode: 458   score: 31.0 global_step 16026   epsilon: 0.20135613247793666\n",
      "episode: 459   score: 137.0 global_step 16163   epsilon: 0.19861622766980452\n",
      "episode: 460   score: 80.0 global_step 16243   epsilon: 0.19703355783429652\n",
      "episode: 461   score: 68.0 global_step 16311   epsilon: 0.19569820820696265\n",
      "episode: 462   score: 86.0 global_step 16397   epsilon: 0.1940223363996278\n",
      "episode: 463   score: 26.0 global_step 16423   epsilon: 0.193518508393414\n",
      "episode: 464   score: 44.0 global_step 16467   epsilon: 0.19266885508123827\n",
      "episode: 465   score: 169.0 global_step 16636   epsilon: 0.18943995107540673\n",
      "episode: 466   score: 227.0 global_step 16863   epsilon: 0.18518789501037913\n",
      "episode: 467   score: 127.0 global_step 16990   epsilon: 0.18285076408112777\n",
      "episode: 468   score: 120.0 global_step 17110   epsilon: 0.18066955925475753\n",
      "episode: 469   score: 29.0 global_step 17139   epsilon: 0.18014635039159177\n",
      "episode: 470   score: 85.0 global_step 17224   epsilon: 0.17862151988133407\n",
      "episode: 471   score: 22.0 global_step 17246   epsilon: 0.1782289648783596\n",
      "episode: 472   score: 19.0 global_step 17265   epsilon: 0.17789063444398584\n",
      "episode: 473   score: 16.0 global_step 17281   epsilon: 0.17760622279805038\n",
      "episode: 474   score: 34.0 global_step 17315   epsilon: 0.17700335694947447\n",
      "episode: 475   score: 63.0 global_step 17378   epsilon: 0.1758916856578048\n",
      "episode: 476   score: 23.0 global_step 17401   epsilon: 0.1754875794754081\n",
      "episode: 477   score: 155.0 global_step 17556   epsilon: 0.17278836002417308\n",
      "episode: 478   score: 152.0 global_step 17708   epsilon: 0.17018170736626947\n",
      "episode: 479   score: 35.0 global_step 17743   epsilon: 0.1695870828586977\n",
      "episode: 480   score: 126.0 global_step 17869   epsilon: 0.16746358556618657\n",
      "episode: 481   score: 117.0 global_step 17986   epsilon: 0.16551558225554897\n",
      "episode: 482   score: 21.0 global_step 18007   epsilon: 0.16516834689549842\n",
      "episode: 483   score: 24.0 global_step 18031   epsilon: 0.16477239839346142\n",
      "episode: 484   score: 85.0 global_step 18116   epsilon: 0.16337769914047884\n",
      "episode: 485   score: 24.0 global_step 18140   epsilon: 0.16298604325448843\n",
      "episode: 486   score: 23.0 global_step 18163   epsilon: 0.16261158742118853\n",
      "episode: 487   score: 28.0 global_step 18191   epsilon: 0.16215688911582696\n",
      "episode: 488   score: 22.0 global_step 18213   epsilon: 0.16180051829258305\n",
      "episode: 489   score: 21.0 global_step 18234   epsilon: 0.16146107677015917\n",
      "episode: 490   score: 70.0 global_step 18304   epsilon: 0.16033473969417752\n",
      "episode: 491   score: 376.0 global_step 18680   epsilon: 0.15441779333459196\n",
      "episode: 492   score: 159.0 global_step 18839   epsilon: 0.1519818457263236\n",
      "episode: 493   score: 224.0 global_step 19063   epsilon: 0.14861513201649726\n",
      "episode: 494   score: 100.0 global_step 19163   epsilon: 0.14713631317246398\n",
      "episode: 495   score: 29.0 global_step 19192   epsilon: 0.1467102147004085\n",
      "episode: 496   score: 26.0 global_step 19218   epsilon: 0.1463292445691579\n",
      "episode: 497   score: 105.0 global_step 19323   epsilon: 0.14480074971686288\n",
      "episode: 498   score: 126.0 global_step 19449   epsilon: 0.14298761634140686\n",
      "episode: 499   score: 258.0 global_step 19707   epsilon: 0.13934553857004037\n",
      "episode: 500   score: 97.0 global_step 19804   epsilon: 0.13800035427727206\n",
      "episode: 501   score: 256.0 global_step 20060   epsilon: 0.13451220955670937\n",
      "episode: 502   score: 28.0 global_step 20088   epsilon: 0.134136083385716\n",
      "episode: 503   score: 93.0 global_step 20181   epsilon: 0.1328943387846676\n",
      "episode: 504   score: 500.0 global_step 20681   epsilon: 0.1264126893483544\n",
      "episode: 505   score: 318.0 global_step 20999   epsilon: 0.12245581572746363\n",
      "episode: 506   score: 127.0 global_step 21126   epsilon: 0.1209103838600765\n",
      "episode: 507   score: 17.0 global_step 21143   epsilon: 0.12070500056344617\n",
      "episode: 508   score: 21.0 global_step 21164   epsilon: 0.1204517733822987\n",
      "episode: 509   score: 227.0 global_step 21391   epsilon: 0.11774818477468942\n",
      "episode: 510   score: 44.0 global_step 21435   epsilon: 0.11723120510164903\n",
      "episode: 511   score: 28.0 global_step 21463   epsilon: 0.11690340047751023\n",
      "episode: 512   score: 23.0 global_step 21486   epsilon: 0.11663481821508276\n",
      "episode: 513   score: 15.0 global_step 21501   epsilon: 0.11645998840126634\n",
      "episode: 514   score: 19.0 global_step 21520   epsilon: 0.1162389134570795\n",
      "episode: 515   score: 20.0 global_step 21540   epsilon: 0.1160066563516449\n",
      "episode: 516   score: 22.0 global_step 21562   epsilon: 0.11575170950448206\n",
      "episode: 517   score: 160.0 global_step 21722   epsilon: 0.11391432852888889\n",
      "episode: 518   score: 222.0 global_step 21944   epsilon: 0.11141317095152757\n",
      "episode: 519   score: 248.0 global_step 22192   epsilon: 0.10868396982972502\n",
      "episode: 520   score: 454.0 global_step 22646   epsilon: 0.10385981336551058\n",
      "episode: 521   score: 137.0 global_step 22783   epsilon: 0.1024465661079776\n",
      "episode: 522   score: 79.0 global_step 22862   epsilon: 0.10164038652842407\n",
      "episode: 523   score: 266.0 global_step 23128   epsilon: 0.09897226221915671\n",
      "episode: 524   score: 17.0 global_step 23145   epsilon: 0.09880414390838319\n",
      "episode: 525   score: 20.0 global_step 23165   epsilon: 0.098606723235851\n",
      "episode: 526   score: 18.0 global_step 23183   epsilon: 0.0984293819218801\n",
      "episode: 527   score: 415.0 global_step 23598   epsilon: 0.09442796617353144\n",
      "episode: 528   score: 15.0 global_step 23613   epsilon: 0.0942864233306838\n",
      "episode: 529   score: 14.0 global_step 23627   epsilon: 0.09415450810435527\n",
      "episode: 530   score: 11.0 global_step 23638   epsilon: 0.09405098991488757\n",
      "episode: 531   score: 14.0 global_step 23652   epsilon: 0.09391940408118239\n",
      "episode: 532   score: 11.0 global_step 23663   epsilon: 0.09381614437687175\n",
      "episode: 533   score: 15.0 global_step 23678   epsilon: 0.0936755186245845\n",
      "episode: 534   score: 14.0 global_step 23692   epsilon: 0.09354445810914354\n",
      "episode: 535   score: 18.0 global_step 23710   epsilon: 0.09337622113126434\n",
      "episode: 536   score: 20.0 global_step 23730   epsilon: 0.0931896459974183\n",
      "episode: 537   score: 102.0 global_step 23832   epsilon: 0.09224389584577203\n",
      "episode: 538   score: 167.0 global_step 23999   epsilon: 0.09071613867634101\n",
      "episode: 539   score: 137.0 global_step 24136   epsilon: 0.08948174078899707\n",
      "episode: 540   score: 29.0 global_step 24165   epsilon: 0.0892226067098228\n",
      "episode: 541   score: 27.0 global_step 24192   epsilon: 0.08898201858223624\n",
      "episode: 542   score: 23.0 global_step 24215   epsilon: 0.08877758490649573\n",
      "episode: 543   score: 20.0 global_step 24235   epsilon: 0.08860019831293066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 544   score: 20.0 global_step 24255   epsilon: 0.08842316615572028\n",
      "episode: 545   score: 18.0 global_step 24273   epsilon: 0.08826413967195798\n",
      "episode: 546   score: 21.0 global_step 24294   epsilon: 0.08807897021600171\n",
      "episode: 547   score: 18.0 global_step 24312   epsilon: 0.08792056275859188\n",
      "episode: 548   score: 21.0 global_step 24333   epsilon: 0.0877361140930989\n",
      "episode: 549   score: 34.0 global_step 24367   epsilon: 0.08743830298017621\n",
      "episode: 550   score: 30.0 global_step 24397   epsilon: 0.08717636807309365\n",
      "episode: 551   score: 111.0 global_step 24508   epsilon: 0.08621401321982554\n",
      "episode: 552   score: 194.0 global_step 24702   epsilon: 0.08455749868334705\n",
      "episode: 553   score: 170.0 global_step 24872   epsilon: 0.08313210015203104\n",
      "episode: 554   score: 189.0 global_step 25061   epsilon: 0.0815755810729269\n",
      "episode: 555   score: 257.0 global_step 25318   epsilon: 0.0795056970852523\n",
      "episode: 556   score: 128.0 global_step 25446   epsilon: 0.07849445932889014\n",
      "episode: 557   score: 205.0 global_step 25651   epsilon: 0.07690162560011718\n",
      "episode: 558   score: 145.0 global_step 25796   epsilon: 0.07579454242477714\n",
      "episode: 559   score: 161.0 global_step 25957   epsilon: 0.07458396109215071\n",
      "episode: 560   score: 25.0 global_step 25982   epsilon: 0.07439772476985483\n",
      "episode: 561   score: 19.0 global_step 26001   epsilon: 0.0742564962408389\n",
      "episode: 562   score: 17.0 global_step 26018   epsilon: 0.07413036113558763\n",
      "episode: 563   score: 20.0 global_step 26038   epsilon: 0.07398224117652989\n",
      "episode: 564   score: 205.0 global_step 26243   epsilon: 0.0724809707673353\n",
      "episode: 565   score: 487.0 global_step 26730   epsilon: 0.06903555212367846\n",
      "episode: 566   score: 477.0 global_step 27207   epsilon: 0.0658197032444558\n",
      "episode: 567   score: 16.0 global_step 27223   epsilon: 0.06571447066606151\n",
      "episode: 568   score: 22.0 global_step 27245   epsilon: 0.06557005052987118\n",
      "episode: 569   score: 75.0 global_step 27320   epsilon: 0.06508009030014009\n",
      "episode: 570   score: 116.0 global_step 27436   epsilon: 0.06432948564597656\n",
      "episode: 571   score: 111.0 global_step 27547   epsilon: 0.06361934143960488\n",
      "episode: 572   score: 100.0 global_step 27647   epsilon: 0.06298628692026145\n",
      "episode: 573   score: 31.0 global_step 27678   epsilon: 0.06279132203411752\n",
      "episode: 574   score: 113.0 global_step 27791   epsilon: 0.062085738868623154\n",
      "episode: 575   score: 260.0 global_step 28051   epsilon: 0.060492235298785495\n",
      "episode: 576   score: 314.0 global_step 28365   epsilon: 0.058622198833120275\n",
      "episode: 577   score: 487.0 global_step 28852   epsilon: 0.05583556373906035\n",
      "episode: 578   score: 184.0 global_step 29036   epsilon: 0.05481753306935385\n",
      "episode: 579   score: 217.0 global_step 29253   epsilon: 0.053640748058852765\n",
      "episode: 580   score: 145.0 global_step 29398   epsilon: 0.05286853070681126\n",
      "episode: 581   score: 176.0 global_step 29574   epsilon: 0.05194613930146404\n",
      "episode: 582   score: 124.0 global_step 29698   epsilon: 0.05130595252557979\n",
      "episode: 583   score: 203.0 global_step 29901   epsilon: 0.050274890820715915\n",
      "episode: 584   score: 274.0 global_step 30175   epsilon: 0.04891599278959844\n",
      "episode: 585   score: 176.0 global_step 30351   epsilon: 0.04806256087594512\n",
      "episode: 586   score: 137.0 global_step 30488   epsilon: 0.04740856121864845\n",
      "episode: 587   score: 135.0 global_step 30623   epsilon: 0.04677281479853394\n",
      "episode: 588   score: 150.0 global_step 30773   epsilon: 0.046076423747243946\n",
      "episode: 589   score: 208.0 global_step 30981   epsilon: 0.045127885700714264\n",
      "episode: 590   score: 205.0 global_step 31186   epsilon: 0.044212136754013115\n",
      "episode: 591   score: 205.0 global_step 31391   epsilon: 0.04331497046679983\n",
      "episode: 592   score: 249.0 global_step 31640   epsilon: 0.04224969219431612\n",
      "episode: 593   score: 213.0 global_step 31853   epsilon: 0.041359246144926566\n",
      "episode: 594   score: 215.0 global_step 32068   epsilon: 0.040479469849587196\n",
      "episode: 595   score: 39.0 global_step 32107   epsilon: 0.040321899500436235\n",
      "episode: 596   score: 68.0 global_step 32175   epsilon: 0.04004862709921112\n",
      "episode: 597   score: 15.0 global_step 32190   epsilon: 0.03998859619140411\n",
      "episode: 598   score: 310.0 global_step 32500   epsilon: 0.03876790711485853\n",
      "episode: 599   score: 107.0 global_step 32607   epsilon: 0.03835528136185952\n",
      "episode: 600   score: 22.0 global_step 32629   epsilon: 0.038270988284524285\n",
      "episode: 601   score: 22.0 global_step 32651   epsilon: 0.038186880457371945\n",
      "episode: 602   score: 129.0 global_step 32780   epsilon: 0.0376974091037915\n",
      "episode: 603   score: 304.0 global_step 33084   epsilon: 0.036568596316466875\n",
      "episode: 604   score: 323.0 global_step 33407   epsilon: 0.03540624556068364\n",
      "episode: 605   score: 226.0 global_step 33633   epsilon: 0.03461499960679659\n",
      "episode: 606   score: 124.0 global_step 33757   epsilon: 0.03418840264899563\n",
      "episode: 607   score: 133.0 global_step 33890   epsilon: 0.033736684889609084\n",
      "episode: 608   score: 272.0 global_step 34162   epsilon: 0.032831369895812985\n",
      "episode: 609   score: 165.0 global_step 34327   epsilon: 0.03229407033898829\n",
      "episode: 610   score: 500.0 global_step 34827   epsilon: 0.03071899314064245\n",
      "episode: 611   score: 100.0 global_step 34927   epsilon: 0.030413318844157853\n",
      "episode: 612   score: 17.0 global_step 34944   epsilon: 0.030361657543562594\n",
      "episode: 613   score: 24.0 global_step 34968   epsilon: 0.03028887330221313\n",
      "episode: 614   score: 116.0 global_step 35084   epsilon: 0.029939534984378006\n",
      "episode: 615   score: 500.0 global_step 35584   epsilon: 0.028479295429934562\n",
      "episode: 616   score: 203.0 global_step 35787   epsilon: 0.027906965915446547\n",
      "episode: 617   score: 341.0 global_step 36128   epsilon: 0.026971334772592302\n",
      "episode: 618   score: 259.0 global_step 36387   epsilon: 0.026281711888601483\n",
      "episode: 619   score: 171.0 global_step 36558   epsilon: 0.02583609323261361\n",
      "episode: 620   score: 180.0 global_step 36738   epsilon: 0.025375181162253197\n",
      "episode: 621   score: 254.0 global_step 36992   epsilon: 0.024738736800096355\n",
      "episode: 622   score: 244.0 global_step 37236   epsilon: 0.024142386861524836\n",
      "episode: 623   score: 190.0 global_step 37426   epsilon: 0.02368798923870927\n",
      "episode: 624   score: 198.0 global_step 37624   epsilon: 0.023223556883756675\n",
      "episode: 625   score: 182.0 global_step 37806   epsilon: 0.022804690451955115\n",
      "episode: 626   score: 11.0 global_step 37817   epsilon: 0.022779617831275693\n",
      "episode: 627   score: 11.0 global_step 37828   epsilon: 0.022754572776693217\n",
      "episode: 628   score: 10.0 global_step 37838   epsilon: 0.0227318284407442\n",
      "episode: 629   score: 10.0 global_step 37848   epsilon: 0.022709106838898915\n",
      "episode: 630   score: 15.0 global_step 37863   epsilon: 0.022675067012873206\n",
      "episode: 631   score: 16.0 global_step 37879   epsilon: 0.022638814103039112\n",
      "episode: 632   score: 229.0 global_step 38108   epsilon: 0.02212625088075068\n",
      "episode: 633   score: 11.0 global_step 38119   epsilon: 0.02210192417056974\n",
      "episode: 634   score: 11.0 global_step 38130   epsilon: 0.022077624206394322\n",
      "episode: 635   score: 11.0 global_step 38141   epsilon: 0.02205335095881853\n",
      "episode: 636   score: 10.0 global_step 38151   epsilon: 0.022031307529221705\n",
      "episode: 637   score: 11.0 global_step 38162   epsilon: 0.022007085204524265\n",
      "episode: 638   score: 16.0 global_step 38178   epsilon: 0.021971900264379316\n",
      "episode: 639   score: 16.0 global_step 38194   epsilon: 0.021936771577936366\n",
      "episode: 640   score: 24.0 global_step 38218   epsilon: 0.021884183827262153\n",
      "episode: 641   score: 106.0 global_step 38324   epsilon: 0.021653425122475693\n",
      "episode: 642   score: 500.0 global_step 38824   epsilon: 0.02059732362091541\n",
      "episode: 643   score: 368.0 global_step 39192   epsilon: 0.019853082920250512\n",
      "episode: 644   score: 288.0 global_step 39480   epsilon: 0.019289441348546446\n",
      "episode: 645   score: 392.0 global_step 39872   epsilon: 0.018547887583911533\n",
      "episode: 646   score: 70.0 global_step 39942   epsilon: 0.018418499288696356\n",
      "episode: 647   score: 355.0 global_step 40297   epsilon: 0.01777608083924485\n",
      "episode: 648   score: 316.0 global_step 40613   epsilon: 0.017223111960030194\n",
      "episode: 649   score: 500.0 global_step 41113   epsilon: 0.01638308991734423\n",
      "episode: 650   score: 186.0 global_step 41299   epsilon: 0.0160811659462161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 651   score: 500.0 global_step 41799   epsilon: 0.015296839983622272\n",
      "episode: 652   score: 500.0 global_step 42299   epsilon: 0.01455076791491002\n",
      "episode: 653   score: 500.0 global_step 42799   epsilon: 0.013841083984683157\n",
      "episode: 654   score: 500.0 global_step 43299   epsilon: 0.013166013435947055\n",
      "episode: 655   score: 500.0 global_step 43799   epsilon: 0.01252386807184786\n",
      "episode: 656   score: 500.0 global_step 44299   epsilon: 0.0119130420338788\n",
      "episode: 657   score: 169.0 global_step 44468   epsilon: 0.011713393423683808\n",
      "episode: 658   score: 204.0 global_step 44672   epsilon: 0.011476849323958434\n",
      "episode: 659   score: 147.0 global_step 44819   epsilon: 0.011309365288325523\n",
      "episode: 660   score: 13.0 global_step 44832   epsilon: 0.011294671931521958\n",
      "episode: 661   score: 17.0 global_step 44849   epsilon: 0.011275486342314508\n",
      "episode: 662   score: 500.0 global_step 45349   epsilon: 0.010725547568675385\n",
      "episode: 663   score: 22.0 global_step 45371   epsilon: 0.010701976123529683\n",
      "episode: 664   score: 15.0 global_step 45386   epsilon: 0.010685934391551384\n",
      "episode: 665   score: 17.0 global_step 45403   epsilon: 0.010667782828692629\n",
      "episode: 666   score: 222.0 global_step 45625   epsilon: 0.010433555877612782\n",
      "episode: 667   score: 292.0 global_step 45917   epsilon: 0.010133286303950773\n",
      "episode: 668   score: 315.0 global_step 46232   epsilon: 0.009999399224421553\n",
      "episode: 669   score: 21.0 global_step 46253   epsilon: 0.009999399224421553\n",
      "episode: 670   score: 18.0 global_step 46271   epsilon: 0.009999399224421553\n",
      "episode: 671   score: 18.0 global_step 46289   epsilon: 0.009999399224421553\n",
      "episode: 672   score: 24.0 global_step 46313   epsilon: 0.009999399224421553\n",
      "episode: 673   score: 500.0 global_step 46813   epsilon: 0.009999399224421553\n",
      "episode: 674   score: 166.0 global_step 46979   epsilon: 0.009999399224421553\n",
      "episode: 675   score: 244.0 global_step 47223   epsilon: 0.009999399224421553\n",
      "episode: 676   score: 17.0 global_step 47240   epsilon: 0.009999399224421553\n",
      "episode: 677   score: 18.0 global_step 47258   epsilon: 0.009999399224421553\n",
      "episode: 678   score: 16.0 global_step 47274   epsilon: 0.009999399224421553\n",
      "episode: 679   score: 20.0 global_step 47294   epsilon: 0.009999399224421553\n",
      "episode: 680   score: 240.0 global_step 47534   epsilon: 0.009999399224421553\n",
      "episode: 681   score: 500.0 global_step 48034   epsilon: 0.009999399224421553\n",
      "episode: 682   score: 346.0 global_step 48380   epsilon: 0.009999399224421553\n",
      "episode: 683   score: 500.0 global_step 48880   epsilon: 0.009999399224421553\n",
      "episode: 684   score: 356.0 global_step 49236   epsilon: 0.009999399224421553\n",
      "episode: 685   score: 500.0 global_step 49736   epsilon: 0.009999399224421553\n",
      "episode: 686   score: 268.0 global_step 50004   epsilon: 0.009999399224421553\n",
      "episode: 687   score: 254.0 global_step 50258   epsilon: 0.009999399224421553\n",
      "episode: 688   score: 177.0 global_step 50435   epsilon: 0.009999399224421553\n",
      "episode: 689   score: 19.0 global_step 50454   epsilon: 0.009999399224421553\n",
      "episode: 690   score: 22.0 global_step 50476   epsilon: 0.009999399224421553\n",
      "episode: 691   score: 16.0 global_step 50492   epsilon: 0.009999399224421553\n",
      "episode: 692   score: 17.0 global_step 50509   epsilon: 0.009999399224421553\n",
      "episode: 693   score: 16.0 global_step 50525   epsilon: 0.009999399224421553\n",
      "episode: 694   score: 500.0 global_step 51025   epsilon: 0.009999399224421553\n",
      "episode: 695   score: 149.0 global_step 51174   epsilon: 0.009999399224421553\n",
      "episode: 696   score: 149.0 global_step 51323   epsilon: 0.009999399224421553\n",
      "episode: 697   score: 124.0 global_step 51447   epsilon: 0.009999399224421553\n",
      "episode: 698   score: 129.0 global_step 51576   epsilon: 0.009999399224421553\n",
      "episode: 699   score: 16.0 global_step 51592   epsilon: 0.009999399224421553\n",
      "episode: 700   score: 15.0 global_step 51607   epsilon: 0.009999399224421553\n",
      "episode: 701   score: 17.0 global_step 51624   epsilon: 0.009999399224421553\n",
      "episode: 702   score: 159.0 global_step 51783   epsilon: 0.009999399224421553\n",
      "episode: 703   score: 440.0 global_step 52223   epsilon: 0.009999399224421553\n",
      "episode: 704   score: 210.0 global_step 52433   epsilon: 0.009999399224421553\n",
      "episode: 705   score: 14.0 global_step 52447   epsilon: 0.009999399224421553\n",
      "episode: 706   score: 14.0 global_step 52461   epsilon: 0.009999399224421553\n",
      "episode: 707   score: 15.0 global_step 52476   epsilon: 0.009999399224421553\n",
      "episode: 708   score: 78.0 global_step 52554   epsilon: 0.009999399224421553\n",
      "episode: 709   score: 194.0 global_step 52748   epsilon: 0.009999399224421553\n",
      "episode: 710   score: 165.0 global_step 52913   epsilon: 0.009999399224421553\n",
      "episode: 711   score: 19.0 global_step 52932   epsilon: 0.009999399224421553\n",
      "episode: 712   score: 20.0 global_step 52952   epsilon: 0.009999399224421553\n",
      "episode: 713   score: 18.0 global_step 52970   epsilon: 0.009999399224421553\n",
      "episode: 714   score: 19.0 global_step 52989   epsilon: 0.009999399224421553\n",
      "episode: 715   score: 19.0 global_step 53008   epsilon: 0.009999399224421553\n",
      "episode: 716   score: 123.0 global_step 53131   epsilon: 0.009999399224421553\n",
      "episode: 717   score: 133.0 global_step 53264   epsilon: 0.009999399224421553\n",
      "episode: 718   score: 239.0 global_step 53503   epsilon: 0.009999399224421553\n",
      "episode: 719   score: 230.0 global_step 53733   epsilon: 0.009999399224421553\n",
      "episode: 720   score: 208.0 global_step 53941   epsilon: 0.009999399224421553\n",
      "episode: 721   score: 500.0 global_step 54441   epsilon: 0.009999399224421553\n",
      "episode: 722   score: 302.0 global_step 54743   epsilon: 0.009999399224421553\n",
      "episode: 723   score: 245.0 global_step 54988   epsilon: 0.009999399224421553\n",
      "episode: 724   score: 467.0 global_step 55455   epsilon: 0.009999399224421553\n",
      "episode: 725   score: 500.0 global_step 55955   epsilon: 0.009999399224421553\n",
      "episode: 726   score: 406.0 global_step 56361   epsilon: 0.009999399224421553\n",
      "episode: 727   score: 176.0 global_step 56537   epsilon: 0.009999399224421553\n",
      "episode: 728   score: 226.0 global_step 56763   epsilon: 0.009999399224421553\n",
      "episode: 729   score: 175.0 global_step 56938   epsilon: 0.009999399224421553\n",
      "episode: 730   score: 17.0 global_step 56955   epsilon: 0.009999399224421553\n",
      "episode: 731   score: 337.0 global_step 57292   epsilon: 0.009999399224421553\n",
      "episode: 732   score: 176.0 global_step 57468   epsilon: 0.009999399224421553\n",
      "episode: 733   score: 176.0 global_step 57644   epsilon: 0.009999399224421553\n",
      "episode: 734   score: 159.0 global_step 57803   epsilon: 0.009999399224421553\n",
      "episode: 735   score: 201.0 global_step 58004   epsilon: 0.009999399224421553\n",
      "episode: 736   score: 15.0 global_step 58019   epsilon: 0.009999399224421553\n",
      "episode: 737   score: 12.0 global_step 58031   epsilon: 0.009999399224421553\n",
      "episode: 738   score: 20.0 global_step 58051   epsilon: 0.009999399224421553\n",
      "episode: 739   score: 70.0 global_step 58121   epsilon: 0.009999399224421553\n",
      "episode: 740   score: 153.0 global_step 58274   epsilon: 0.009999399224421553\n",
      "episode: 741   score: 144.0 global_step 58418   epsilon: 0.009999399224421553\n",
      "episode: 742   score: 114.0 global_step 58532   epsilon: 0.009999399224421553\n",
      "episode: 743   score: 114.0 global_step 58646   epsilon: 0.009999399224421553\n",
      "episode: 744   score: 136.0 global_step 58782   epsilon: 0.009999399224421553\n",
      "episode: 745   score: 178.0 global_step 58960   epsilon: 0.009999399224421553\n",
      "episode: 746   score: 159.0 global_step 59119   epsilon: 0.009999399224421553\n",
      "episode: 747   score: 161.0 global_step 59280   epsilon: 0.009999399224421553\n",
      "episode: 748   score: 152.0 global_step 59432   epsilon: 0.009999399224421553\n",
      "episode: 749   score: 134.0 global_step 59566   epsilon: 0.009999399224421553\n",
      "episode: 750   score: 143.0 global_step 59709   epsilon: 0.009999399224421553\n",
      "episode: 751   score: 22.0 global_step 59731   epsilon: 0.009999399224421553\n",
      "episode: 752   score: 124.0 global_step 59855   epsilon: 0.009999399224421553\n",
      "episode: 753   score: 136.0 global_step 59991   epsilon: 0.009999399224421553\n",
      "episode: 754   score: 130.0 global_step 60121   epsilon: 0.009999399224421553\n",
      "episode: 755   score: 137.0 global_step 60258   epsilon: 0.009999399224421553\n",
      "episode: 756   score: 143.0 global_step 60401   epsilon: 0.009999399224421553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 757   score: 133.0 global_step 60534   epsilon: 0.009999399224421553\n",
      "episode: 758   score: 114.0 global_step 60648   epsilon: 0.009999399224421553\n",
      "episode: 759   score: 131.0 global_step 60779   epsilon: 0.009999399224421553\n",
      "episode: 760   score: 131.0 global_step 60910   epsilon: 0.009999399224421553\n",
      "episode: 761   score: 152.0 global_step 61062   epsilon: 0.009999399224421553\n",
      "episode: 762   score: 146.0 global_step 61208   epsilon: 0.009999399224421553\n",
      "episode: 763   score: 134.0 global_step 61342   epsilon: 0.009999399224421553\n",
      "episode: 764   score: 127.0 global_step 61469   epsilon: 0.009999399224421553\n",
      "episode: 765   score: 125.0 global_step 61594   epsilon: 0.009999399224421553\n",
      "episode: 766   score: 143.0 global_step 61737   epsilon: 0.009999399224421553\n",
      "episode: 767   score: 22.0 global_step 61759   epsilon: 0.009999399224421553\n",
      "episode: 768   score: 159.0 global_step 61918   epsilon: 0.009999399224421553\n",
      "episode: 769   score: 183.0 global_step 62101   epsilon: 0.009999399224421553\n",
      "episode: 770   score: 255.0 global_step 62356   epsilon: 0.009999399224421553\n",
      "episode: 771   score: 225.0 global_step 62581   epsilon: 0.009999399224421553\n",
      "episode: 772   score: 401.0 global_step 62982   epsilon: 0.009999399224421553\n",
      "episode: 773   score: 190.0 global_step 63172   epsilon: 0.009999399224421553\n",
      "episode: 774   score: 185.0 global_step 63357   epsilon: 0.009999399224421553\n",
      "episode: 775   score: 147.0 global_step 63504   epsilon: 0.009999399224421553\n",
      "episode: 776   score: 156.0 global_step 63660   epsilon: 0.009999399224421553\n",
      "episode: 777   score: 167.0 global_step 63827   epsilon: 0.009999399224421553\n",
      "episode: 778   score: 156.0 global_step 63983   epsilon: 0.009999399224421553\n",
      "episode: 779   score: 142.0 global_step 64125   epsilon: 0.009999399224421553\n",
      "episode: 780   score: 155.0 global_step 64280   epsilon: 0.009999399224421553\n",
      "episode: 781   score: 130.0 global_step 64410   epsilon: 0.009999399224421553\n",
      "episode: 782   score: 164.0 global_step 64574   epsilon: 0.009999399224421553\n",
      "episode: 783   score: 156.0 global_step 64730   epsilon: 0.009999399224421553\n",
      "episode: 784   score: 164.0 global_step 64894   epsilon: 0.009999399224421553\n",
      "episode: 785   score: 146.0 global_step 65040   epsilon: 0.009999399224421553\n",
      "episode: 786   score: 150.0 global_step 65190   epsilon: 0.009999399224421553\n",
      "episode: 787   score: 159.0 global_step 65349   epsilon: 0.009999399224421553\n",
      "episode: 788   score: 171.0 global_step 65520   epsilon: 0.009999399224421553\n",
      "episode: 789   score: 14.0 global_step 65534   epsilon: 0.009999399224421553\n",
      "episode: 790   score: 75.0 global_step 65609   epsilon: 0.009999399224421553\n",
      "episode: 791   score: 13.0 global_step 65622   epsilon: 0.009999399224421553\n",
      "episode: 792   score: 15.0 global_step 65637   epsilon: 0.009999399224421553\n",
      "episode: 793   score: 82.0 global_step 65719   epsilon: 0.009999399224421553\n",
      "episode: 794   score: 477.0 global_step 66196   epsilon: 0.009999399224421553\n",
      "episode: 795   score: 500.0 global_step 66696   epsilon: 0.009999399224421553\n",
      "episode: 796   score: 144.0 global_step 66840   epsilon: 0.009999399224421553\n",
      "episode: 797   score: 186.0 global_step 67026   epsilon: 0.009999399224421553\n",
      "episode: 798   score: 219.0 global_step 67245   epsilon: 0.009999399224421553\n",
      "episode: 799   score: 168.0 global_step 67413   epsilon: 0.009999399224421553\n",
      "episode: 800   score: 395.0 global_step 67808   epsilon: 0.009999399224421553\n",
      "episode: 801   score: 248.0 global_step 68056   epsilon: 0.009999399224421553\n",
      "episode: 802   score: 198.0 global_step 68254   epsilon: 0.009999399224421553\n",
      "episode: 803   score: 297.0 global_step 68551   epsilon: 0.009999399224421553\n",
      "episode: 804   score: 162.0 global_step 68713   epsilon: 0.009999399224421553\n",
      "episode: 805   score: 76.0 global_step 68789   epsilon: 0.009999399224421553\n",
      "episode: 806   score: 13.0 global_step 68802   epsilon: 0.009999399224421553\n",
      "episode: 807   score: 500.0 global_step 69302   epsilon: 0.009999399224421553\n",
      "episode: 808   score: 378.0 global_step 69680   epsilon: 0.009999399224421553\n",
      "episode: 809   score: 404.0 global_step 70084   epsilon: 0.009999399224421553\n",
      "episode: 810   score: 500.0 global_step 70584   epsilon: 0.009999399224421553\n",
      "episode: 811   score: 78.0 global_step 70662   epsilon: 0.009999399224421553\n",
      "episode: 812   score: 22.0 global_step 70684   epsilon: 0.009999399224421553\n",
      "episode: 813   score: 500.0 global_step 71184   epsilon: 0.009999399224421553\n",
      "episode: 814   score: 500.0 global_step 71684   epsilon: 0.009999399224421553\n",
      "episode: 815   score: 471.0 global_step 72155   epsilon: 0.009999399224421553\n",
      "episode: 816   score: 500.0 global_step 72655   epsilon: 0.009999399224421553\n",
      "episode: 817   score: 485.0 global_step 73140   epsilon: 0.009999399224421553\n",
      "episode: 818   score: 17.0 global_step 73157   epsilon: 0.009999399224421553\n",
      "episode: 819   score: 13.0 global_step 73170   epsilon: 0.009999399224421553\n",
      "episode: 820   score: 500.0 global_step 73670   epsilon: 0.009999399224421553\n",
      "episode: 821   score: 268.0 global_step 73938   epsilon: 0.009999399224421553\n",
      "episode: 822   score: 376.0 global_step 74314   epsilon: 0.009999399224421553\n",
      "episode: 823   score: 500.0 global_step 74814   epsilon: 0.009999399224421553\n",
      "episode: 824   score: 500.0 global_step 75314   epsilon: 0.009999399224421553\n",
      "episode: 825   score: 325.0 global_step 75639   epsilon: 0.009999399224421553\n",
      "episode: 826   score: 500.0 global_step 76139   epsilon: 0.009999399224421553\n",
      "episode: 827   score: 401.0 global_step 76540   epsilon: 0.009999399224421553\n",
      "episode: 828   score: 500.0 global_step 77040   epsilon: 0.009999399224421553\n",
      "episode: 829   score: 500.0 global_step 77540   epsilon: 0.009999399224421553\n",
      "episode: 830   score: 500.0 global_step 78040   epsilon: 0.009999399224421553\n",
      "episode: 831   score: 236.0 global_step 78276   epsilon: 0.009999399224421553\n",
      "episode: 832   score: 248.0 global_step 78524   epsilon: 0.009999399224421553\n",
      "episode: 833   score: 385.0 global_step 78909   epsilon: 0.009999399224421553\n",
      "episode: 834   score: 500.0 global_step 79409   epsilon: 0.009999399224421553\n",
      "episode: 835   score: 500.0 global_step 79909   epsilon: 0.009999399224421553\n",
      "episode: 836   score: 391.0 global_step 80300   epsilon: 0.009999399224421553\n",
      "episode: 837   score: 500.0 global_step 80800   epsilon: 0.009999399224421553\n",
      "episode: 838   score: 500.0 global_step 81300   epsilon: 0.009999399224421553\n",
      "episode: 839   score: 75.0 global_step 81375   epsilon: 0.009999399224421553\n",
      "episode: 840   score: 282.0 global_step 81657   epsilon: 0.009999399224421553\n",
      "episode: 841   score: 12.0 global_step 81669   epsilon: 0.009999399224421553\n",
      "episode: 842   score: 13.0 global_step 81682   epsilon: 0.009999399224421553\n",
      "episode: 843   score: 74.0 global_step 81756   epsilon: 0.009999399224421553\n",
      "episode: 844   score: 197.0 global_step 81953   epsilon: 0.009999399224421553\n",
      "episode: 845   score: 130.0 global_step 82083   epsilon: 0.009999399224421553\n",
      "episode: 846   score: 137.0 global_step 82220   epsilon: 0.009999399224421553\n",
      "episode: 847   score: 262.0 global_step 82482   epsilon: 0.009999399224421553\n",
      "episode: 848   score: 131.0 global_step 82613   epsilon: 0.009999399224421553\n",
      "episode: 849   score: 168.0 global_step 82781   epsilon: 0.009999399224421553\n",
      "episode: 850   score: 137.0 global_step 82918   epsilon: 0.009999399224421553\n",
      "episode: 851   score: 179.0 global_step 83097   epsilon: 0.009999399224421553\n",
      "episode: 852   score: 164.0 global_step 83261   epsilon: 0.009999399224421553\n",
      "episode: 853   score: 131.0 global_step 83392   epsilon: 0.009999399224421553\n",
      "episode: 854   score: 171.0 global_step 83563   epsilon: 0.009999399224421553\n",
      "episode: 855   score: 153.0 global_step 83716   epsilon: 0.009999399224421553\n",
      "episode: 856   score: 161.0 global_step 83877   epsilon: 0.009999399224421553\n",
      "episode: 857   score: 158.0 global_step 84035   epsilon: 0.009999399224421553\n",
      "episode: 858   score: 174.0 global_step 84209   epsilon: 0.009999399224421553\n",
      "episode: 859   score: 236.0 global_step 84445   epsilon: 0.009999399224421553\n",
      "episode: 860   score: 177.0 global_step 84622   epsilon: 0.009999399224421553\n",
      "episode: 861   score: 191.0 global_step 84813   epsilon: 0.009999399224421553\n",
      "episode: 862   score: 195.0 global_step 85008   epsilon: 0.009999399224421553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 863   score: 161.0 global_step 85169   epsilon: 0.009999399224421553\n",
      "episode: 864   score: 219.0 global_step 85388   epsilon: 0.009999399224421553\n",
      "episode: 865   score: 227.0 global_step 85615   epsilon: 0.009999399224421553\n",
      "episode: 866   score: 259.0 global_step 85874   epsilon: 0.009999399224421553\n",
      "episode: 867   score: 232.0 global_step 86106   epsilon: 0.009999399224421553\n",
      "episode: 868   score: 500.0 global_step 86606   epsilon: 0.009999399224421553\n",
      "episode: 869   score: 187.0 global_step 86793   epsilon: 0.009999399224421553\n",
      "episode: 870   score: 206.0 global_step 86999   epsilon: 0.009999399224421553\n",
      "episode: 871   score: 302.0 global_step 87301   epsilon: 0.009999399224421553\n",
      "episode: 872   score: 234.0 global_step 87535   epsilon: 0.009999399224421553\n",
      "episode: 873   score: 230.0 global_step 87765   epsilon: 0.009999399224421553\n",
      "episode: 874   score: 500.0 global_step 88265   epsilon: 0.009999399224421553\n",
      "episode: 875   score: 445.0 global_step 88710   epsilon: 0.009999399224421553\n",
      "episode: 876   score: 270.0 global_step 88980   epsilon: 0.009999399224421553\n",
      "episode: 877   score: 260.0 global_step 89240   epsilon: 0.009999399224421553\n",
      "episode: 878   score: 260.0 global_step 89500   epsilon: 0.009999399224421553\n",
      "episode: 879   score: 340.0 global_step 89840   epsilon: 0.009999399224421553\n",
      "episode: 880   score: 12.0 global_step 89852   epsilon: 0.009999399224421553\n",
      "episode: 881   score: 13.0 global_step 89865   epsilon: 0.009999399224421553\n",
      "episode: 882   score: 11.0 global_step 89876   epsilon: 0.009999399224421553\n",
      "episode: 883   score: 11.0 global_step 89887   epsilon: 0.009999399224421553\n",
      "episode: 884   score: 15.0 global_step 89902   epsilon: 0.009999399224421553\n",
      "episode: 885   score: 14.0 global_step 89916   epsilon: 0.009999399224421553\n",
      "episode: 886   score: 22.0 global_step 89938   epsilon: 0.009999399224421553\n",
      "episode: 887   score: 79.0 global_step 90017   epsilon: 0.009999399224421553\n",
      "episode: 888   score: 135.0 global_step 90152   epsilon: 0.009999399224421553\n",
      "episode: 889   score: 13.0 global_step 90165   epsilon: 0.009999399224421553\n",
      "episode: 890   score: 13.0 global_step 90178   epsilon: 0.009999399224421553\n",
      "episode: 891   score: 100.0 global_step 90278   epsilon: 0.009999399224421553\n",
      "episode: 892   score: 104.0 global_step 90382   epsilon: 0.009999399224421553\n",
      "episode: 893   score: 130.0 global_step 90512   epsilon: 0.009999399224421553\n",
      "episode: 894   score: 165.0 global_step 90677   epsilon: 0.009999399224421553\n",
      "episode: 895   score: 170.0 global_step 90847   epsilon: 0.009999399224421553\n",
      "episode: 896   score: 148.0 global_step 90995   epsilon: 0.009999399224421553\n",
      "episode: 897   score: 151.0 global_step 91146   epsilon: 0.009999399224421553\n",
      "episode: 898   score: 140.0 global_step 91286   epsilon: 0.009999399224421553\n",
      "episode: 899   score: 139.0 global_step 91425   epsilon: 0.009999399224421553\n",
      "episode: 900   score: 130.0 global_step 91555   epsilon: 0.009999399224421553\n",
      "episode: 901   score: 142.0 global_step 91697   epsilon: 0.009999399224421553\n",
      "episode: 902   score: 143.0 global_step 91840   epsilon: 0.009999399224421553\n",
      "episode: 903   score: 136.0 global_step 91976   epsilon: 0.009999399224421553\n",
      "episode: 904   score: 131.0 global_step 92107   epsilon: 0.009999399224421553\n",
      "episode: 905   score: 132.0 global_step 92239   epsilon: 0.009999399224421553\n",
      "episode: 906   score: 136.0 global_step 92375   epsilon: 0.009999399224421553\n",
      "episode: 907   score: 144.0 global_step 92519   epsilon: 0.009999399224421553\n",
      "episode: 908   score: 139.0 global_step 92658   epsilon: 0.009999399224421553\n",
      "episode: 909   score: 143.0 global_step 92801   epsilon: 0.009999399224421553\n",
      "episode: 910   score: 145.0 global_step 92946   epsilon: 0.009999399224421553\n",
      "episode: 911   score: 144.0 global_step 93090   epsilon: 0.009999399224421553\n",
      "episode: 912   score: 149.0 global_step 93239   epsilon: 0.009999399224421553\n",
      "episode: 913   score: 145.0 global_step 93384   epsilon: 0.009999399224421553\n",
      "episode: 914   score: 151.0 global_step 93535   epsilon: 0.009999399224421553\n",
      "episode: 915   score: 150.0 global_step 93685   epsilon: 0.009999399224421553\n",
      "episode: 916   score: 155.0 global_step 93840   epsilon: 0.009999399224421553\n",
      "episode: 917   score: 168.0 global_step 94008   epsilon: 0.009999399224421553\n",
      "episode: 918   score: 165.0 global_step 94173   epsilon: 0.009999399224421553\n",
      "episode: 919   score: 172.0 global_step 94345   epsilon: 0.009999399224421553\n",
      "episode: 920   score: 178.0 global_step 94523   epsilon: 0.009999399224421553\n",
      "episode: 921   score: 146.0 global_step 94669   epsilon: 0.009999399224421553\n",
      "episode: 922   score: 174.0 global_step 94843   epsilon: 0.009999399224421553\n",
      "episode: 923   score: 237.0 global_step 95080   epsilon: 0.009999399224421553\n",
      "episode: 924   score: 180.0 global_step 95260   epsilon: 0.009999399224421553\n",
      "episode: 925   score: 190.0 global_step 95450   epsilon: 0.009999399224421553\n",
      "episode: 926   score: 500.0 global_step 95950   epsilon: 0.009999399224421553\n",
      "episode: 927   score: 141.0 global_step 96091   epsilon: 0.009999399224421553\n",
      "episode: 928   score: 500.0 global_step 96591   epsilon: 0.009999399224421553\n",
      "episode: 929   score: 467.0 global_step 97058   epsilon: 0.009999399224421553\n",
      "episode: 930   score: 500.0 global_step 97558   epsilon: 0.009999399224421553\n",
      "episode: 931   score: 408.0 global_step 97966   epsilon: 0.009999399224421553\n",
      "episode: 932   score: 189.0 global_step 98155   epsilon: 0.009999399224421553\n",
      "episode: 933   score: 16.0 global_step 98171   epsilon: 0.009999399224421553\n",
      "episode: 934   score: 10.0 global_step 98181   epsilon: 0.009999399224421553\n",
      "episode: 935   score: 9.0 global_step 98190   epsilon: 0.009999399224421553\n",
      "episode: 936   score: 10.0 global_step 98200   epsilon: 0.009999399224421553\n",
      "episode: 937   score: 10.0 global_step 98210   epsilon: 0.009999399224421553\n",
      "episode: 938   score: 11.0 global_step 98221   epsilon: 0.009999399224421553\n",
      "episode: 939   score: 12.0 global_step 98233   epsilon: 0.009999399224421553\n",
      "episode: 940   score: 13.0 global_step 98246   epsilon: 0.009999399224421553\n",
      "episode: 941   score: 16.0 global_step 98262   epsilon: 0.009999399224421553\n",
      "episode: 942   score: 419.0 global_step 98681   epsilon: 0.009999399224421553\n",
      "episode: 943   score: 114.0 global_step 98795   epsilon: 0.009999399224421553\n",
      "episode: 944   score: 119.0 global_step 98914   epsilon: 0.009999399224421553\n",
      "episode: 945   score: 120.0 global_step 99034   epsilon: 0.009999399224421553\n",
      "episode: 946   score: 120.0 global_step 99154   epsilon: 0.009999399224421553\n",
      "episode: 947   score: 122.0 global_step 99276   epsilon: 0.009999399224421553\n",
      "episode: 948   score: 124.0 global_step 99400   epsilon: 0.009999399224421553\n",
      "episode: 949   score: 120.0 global_step 99520   epsilon: 0.009999399224421553\n",
      "episode: 950   score: 123.0 global_step 99643   epsilon: 0.009999399224421553\n",
      "episode: 951   score: 135.0 global_step 99778   epsilon: 0.009999399224421553\n",
      "episode: 952   score: 125.0 global_step 99903   epsilon: 0.009999399224421553\n",
      "episode: 953   score: 131.0 global_step 100034   epsilon: 0.009999399224421553\n",
      "episode: 954   score: 132.0 global_step 100166   epsilon: 0.009999399224421553\n",
      "episode: 955   score: 143.0 global_step 100309   epsilon: 0.009999399224421553\n",
      "episode: 956   score: 127.0 global_step 100436   epsilon: 0.009999399224421553\n",
      "episode: 957   score: 153.0 global_step 100589   epsilon: 0.009999399224421553\n",
      "episode: 958   score: 147.0 global_step 100736   epsilon: 0.009999399224421553\n",
      "episode: 959   score: 159.0 global_step 100895   epsilon: 0.009999399224421553\n",
      "episode: 960   score: 168.0 global_step 101063   epsilon: 0.009999399224421553\n",
      "episode: 961   score: 161.0 global_step 101224   epsilon: 0.009999399224421553\n",
      "episode: 962   score: 169.0 global_step 101393   epsilon: 0.009999399224421553\n",
      "episode: 963   score: 193.0 global_step 101586   epsilon: 0.009999399224421553\n",
      "episode: 964   score: 166.0 global_step 101752   epsilon: 0.009999399224421553\n",
      "episode: 965   score: 161.0 global_step 101913   epsilon: 0.009999399224421553\n",
      "episode: 966   score: 163.0 global_step 102076   epsilon: 0.009999399224421553\n",
      "episode: 967   score: 169.0 global_step 102245   epsilon: 0.009999399224421553\n",
      "episode: 968   score: 175.0 global_step 102420   epsilon: 0.009999399224421553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 969   score: 172.0 global_step 102592   epsilon: 0.009999399224421553\n",
      "episode: 970   score: 183.0 global_step 102775   epsilon: 0.009999399224421553\n",
      "episode: 971   score: 203.0 global_step 102978   epsilon: 0.009999399224421553\n",
      "episode: 972   score: 182.0 global_step 103160   epsilon: 0.009999399224421553\n",
      "episode: 973   score: 320.0 global_step 103480   epsilon: 0.009999399224421553\n",
      "episode: 974   score: 188.0 global_step 103668   epsilon: 0.009999399224421553\n",
      "episode: 975   score: 350.0 global_step 104018   epsilon: 0.009999399224421553\n",
      "episode: 976   score: 202.0 global_step 104220   epsilon: 0.009999399224421553\n",
      "episode: 977   score: 500.0 global_step 104720   epsilon: 0.009999399224421553\n",
      "episode: 978   score: 141.0 global_step 104861   epsilon: 0.009999399224421553\n",
      "episode: 979   score: 11.0 global_step 104872   epsilon: 0.009999399224421553\n",
      "episode: 980   score: 10.0 global_step 104882   epsilon: 0.009999399224421553\n",
      "episode: 981   score: 10.0 global_step 104892   epsilon: 0.009999399224421553\n",
      "episode: 982   score: 10.0 global_step 104902   epsilon: 0.009999399224421553\n",
      "episode: 983   score: 12.0 global_step 104914   epsilon: 0.009999399224421553\n",
      "episode: 984   score: 13.0 global_step 104927   epsilon: 0.009999399224421553\n",
      "episode: 985   score: 302.0 global_step 105229   epsilon: 0.009999399224421553\n",
      "episode: 986   score: 9.0 global_step 105238   epsilon: 0.009999399224421553\n",
      "episode: 987   score: 11.0 global_step 105249   epsilon: 0.009999399224421553\n",
      "episode: 988   score: 11.0 global_step 105260   epsilon: 0.009999399224421553\n",
      "episode: 989   score: 14.0 global_step 105274   epsilon: 0.009999399224421553\n",
      "episode: 990   score: 13.0 global_step 105287   epsilon: 0.009999399224421553\n",
      "episode: 991   score: 22.0 global_step 105309   epsilon: 0.009999399224421553\n",
      "episode: 992   score: 24.0 global_step 105333   epsilon: 0.009999399224421553\n",
      "episode: 993   score: 24.0 global_step 105357   epsilon: 0.009999399224421553\n",
      "episode: 994   score: 500.0 global_step 105857   epsilon: 0.009999399224421553\n",
      "episode: 995   score: 500.0 global_step 106357   epsilon: 0.009999399224421553\n",
      "episode: 996   score: 500.0 global_step 106857   epsilon: 0.009999399224421553\n",
      "episode: 997   score: 500.0 global_step 107357   epsilon: 0.009999399224421553\n",
      "episode: 998   score: 500.0 global_step 107857   epsilon: 0.009999399224421553\n",
      "episode: 999   score: 500.0 global_step 108357   epsilon: 0.009999399224421553\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "agent = DeepSARSAgent()\n",
    "\n",
    "global_step = 0\n",
    "scores, episodes = [], []\n",
    "\n",
    "for e in range(EPISODES):\n",
    "    done = False\n",
    "    score = 0\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1, 4])\n",
    "\n",
    "    while not done:\n",
    "        \n",
    "        # fresh env\n",
    "        global_step += 1\n",
    "\n",
    "        # get action for the current state and go one step in environment\n",
    "        action = agent.get_action(state)\n",
    "        next_state, reward, done,info = env.step(action)\n",
    "        next_state = np.reshape(next_state, [1, 4])\n",
    "        next_action = agent.get_action(next_state)\n",
    "        agent.train_model(state, action, reward, next_state, next_action,\n",
    "                          done)\n",
    "        state = next_state\n",
    "        # every time step we do training\n",
    "        score += reward\n",
    "\n",
    "        state = copy.deepcopy(next_state)\n",
    "\n",
    "        if done:\n",
    "            scores.append(score)\n",
    "            episodes.append(e)\n",
    "            pylab.plot(episodes, scores, 'b')\n",
    "\n",
    "            print(\"episode:\", e, \"  score:\", score, \"global_step\",\n",
    "                  global_step, \"  epsilon:\", agent.epsilon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-5913dc198621>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m# fresh env\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mglobal_step\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[1;31m# get action for the current state and go one step in environment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, mode, **kwargs)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'human'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\gym\\envs\\classic_control\\cartpole.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoletrans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_rotation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreturn_rgb_array\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'rgb_array'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, return_rgb_array)\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0monetime_geoms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreturn_rgb_array\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\pyglet\\window\\win32\\__init__.py\u001b[0m in \u001b[0;36mflip\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    334\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_always_dwm\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dwm_composition_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_interval\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m                     \u001b[0m_dwmapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDwmFlush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in range(EPISODES):\n",
    "    done = False\n",
    "    score = 0\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1, 4])\n",
    "\n",
    "    while not done:\n",
    "        # fresh env\n",
    "        global_step += 1\n",
    "        env.render()\n",
    "        # get action for the current state and go one step in environment\n",
    "        action = agent.get_action(state)\n",
    "        next_state, reward, done,info = env.step(action)\n",
    "        next_state = np.reshape(next_state, [1, 4])\n",
    "        next_action = agent.get_action(next_state)\n",
    "        \n",
    "        state = next_state\n",
    "        # every time step we do training\n",
    "        score += reward\n",
    "\n",
    "        state = copy.deepcopy(next_state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
